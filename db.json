{"meta":{"version":1,"warehouse":"4.0.0"},"models":{"Asset":[{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/avatar.jpg","path":"images/avatar.jpg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/js/algolia-search.js","path":"js/algolia-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/bookmark.js","path":"js/bookmark.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/local-search.js","path":"js/local-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/motion.js","path":"js/motion.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/next-boot.js","path":"js/next-boot.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/utils.js","path":"js/utils.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/anime.min.js","path":"lib/anime.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/schemes/muse.js","path":"js/schemes/muse.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/schemes/pisces.js","path":"js/schemes/pisces.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/all.min.css","path":"lib/font-awesome/css/all.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-brands-400.woff2","path":"lib/font-awesome/webfonts/fa-brands-400.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-solid-900.woff2","path":"lib/font-awesome/webfonts/fa-solid-900.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-regular-400.woff2","path":"lib/font-awesome/webfonts/fa-regular-400.woff2","modified":0,"renderable":1}],"Cache":[{"_id":"source/about/index.md","hash":"4e4b75c948f4cefda4b6adf92fac86ffd70e4c5b","modified":1635866221967},{"_id":"source/tags/index.md","hash":"e7d91cd01037bda07678974366b48ab778592d8b","modified":1635866221972},{"_id":"source/_posts/2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances.md","hash":"a62bc8740e1d3231c99a4eb1979383847e6be980","modified":1635866221912},{"_id":"source/categories/index.md","hash":"e1671eaba7f8173687684cee30ba8054c8f822e1","modified":1635866221970},{"_id":"source/_posts/2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances/dataset.png","hash":"6ad2540bc3265bb799540716added607ddd21655","modified":1635866221947},{"_id":"source/_posts/2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances/docRep.jpg","hash":"c82e5f9da1401a5c03183aa586ba7932a76664a5","modified":1635866221957},{"_id":"source/_posts/2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances/nBow.jpg","hash":"3008125376aed439f0c85c842c6c1c26107c518c","modified":1635866221959},{"_id":"source/_posts/2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances/visualization.png","hash":"e5d00f714514ca2969a29c29facbe5d2e1c0a73d","modified":1635866221965},{"_id":"source/_posts/2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances/prefetch.png","hash":"b597f2e674dd5729835d210c5b47297b773b0176","modified":1635866221963},{"_id":"themes/next/.eslintrc.json","hash":"cc5f297f0322672fe3f684f823bc4659e4a54c41","modified":1601632688000},{"_id":"themes/next/.gitattributes","hash":"a54f902957d49356376b59287b894b1a3d7a003f","modified":1601632688000},{"_id":"themes/next/.editorconfig","hash":"8570735a8d8d034a3a175afd1dd40b39140b3e6a","modified":1601632688000},{"_id":"themes/next/.gitignore","hash":"56f3470755c20311ddd30d421b377697a6e5e68b","modified":1601632688000},{"_id":"themes/next/.stylintrc","hash":"2cf4d637b56d8eb423f59656a11f6403aa90f550","modified":1601632688000},{"_id":"themes/next/.travis.yml","hash":"ecca3b919a5b15886e3eca58aa84aafc395590da","modified":1601632688000},{"_id":"themes/next/LICENSE.md","hash":"18144d8ed58c75af66cb419d54f3f63374cd5c5b","modified":1601632688000},{"_id":"themes/next/_config.yml","hash":"b141d4e7ee3a22d64c1339426c742fe3166021eb","modified":1601879436063},{"_id":"themes/next/README.md","hash":"9b4b7d66aca47f9c65d6321b14eef48d95c4dff1","modified":1601632688000},{"_id":"themes/next/crowdin.yml","hash":"e026078448c77dcdd9ef50256bb6635a8f83dca6","modified":1601632688000},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"e554931b98f251fd49ff1d2443006d9ea2c20461","modified":1601632688000},{"_id":"themes/next/package.json","hash":"62fad6de02adbbba9fb096cbe2dcc15fe25f2435","modified":1601632688000},{"_id":"themes/next/.github/CODE_OF_CONDUCT.md","hash":"aa4cb7aff595ca628cb58160ee1eee117989ec4e","modified":1601632688000},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"1a435c20ae8fa183d49bbf96ac956f7c6c25c8af","modified":1601632688000},{"_id":"themes/next/.github/issue-close-app.yml","hash":"7cba457eec47dbfcfd4086acd1c69eaafca2f0cd","modified":1601632688000},{"_id":"themes/next/.github/config.yml","hash":"1d3f4e8794986817c0fead095c74f756d45f91ed","modified":1601632688000},{"_id":"themes/next/.github/lock.yml","hash":"61173b9522ebac13db2c544e138808295624f7fd","modified":1601632688000},{"_id":"themes/next/.github/release-drafter.yml","hash":"3cc10ce75ecc03a5ce86b00363e2a17eb65d15ea","modified":1601632688000},{"_id":"themes/next/.github/mergeable.yml","hash":"0ee56e23bbc71e1e76427d2bd255a9879bd36e22","modified":1601632688000},{"_id":"themes/next/.github/issue_label_bot.yaml","hash":"fca600ddef6f80c5e61aeed21722d191e5606e5b","modified":1601632688000},{"_id":"themes/next/.github/stale.yml","hash":"fdf82de9284f8bc8e0b0712b4cc1cb081a94de59","modified":1601632688000},{"_id":"themes/next/.github/support.yml","hash":"d75db6ffa7b4ca3b865a925f9de9aef3fc51925c","modified":1601632688000},{"_id":"themes/next/docs/AGPL3.md","hash":"0d2b8c5fa8a614723be0767cc3bca39c49578036","modified":1601632688000},{"_id":"themes/next/gulpfile.js","hash":"1b4fc262b89948937b9e3794de812a7c1f2f3592","modified":1601632688000},{"_id":"themes/next/docs/AUTHORS.md","hash":"10135a2f78ac40e9f46b3add3e360c025400752f","modified":1601632688000},{"_id":"themes/next/docs/ALGOLIA-SEARCH.md","hash":"c7a994b9542040317d8f99affa1405c143a94a38","modified":1601632688000},{"_id":"themes/next/docs/DATA-FILES.md","hash":"cddbdc91ee9e65c37a50bec12194f93d36161616","modified":1601632688000},{"_id":"themes/next/docs/LEANCLOUD-COUNTER-SECURITY.md","hash":"94dc3404ccb0e5f663af2aa883c1af1d6eae553d","modified":1601632688000},{"_id":"themes/next/docs/LICENSE.txt","hash":"368bf2c29d70f27d8726dd914f1b3211cae4bbab","modified":1601632688000},{"_id":"themes/next/docs/INSTALLATION.md","hash":"af88bcce035780aaa061261ed9d0d6c697678618","modified":1601632688000},{"_id":"themes/next/docs/MATH.md","hash":"d645b025ec7fb9fbf799b9bb76af33b9f5b9ed93","modified":1601632688000},{"_id":"themes/next/languages/ar.yml","hash":"9815e84e53d750c8bcbd9193c2d44d8d910e3444","modified":1601632688000},{"_id":"themes/next/docs/UPDATE-FROM-5.1.X.md","hash":"8b6e4b2c9cfcb969833092bdeaed78534082e3e6","modified":1601632688000},{"_id":"themes/next/languages/default.yml","hash":"45bc5118828bdc72dcaa25282cd367c8622758cb","modified":1601632688000},{"_id":"themes/next/languages/es.yml","hash":"c64cf05f356096f1464b4b1439da3c6c9b941062","modified":1601632688000},{"_id":"themes/next/languages/de.yml","hash":"74c59f2744217003b717b59d96e275b54635abf5","modified":1601632688000},{"_id":"themes/next/languages/fr.yml","hash":"752bf309f46a2cd43890b82300b342d7218d625f","modified":1601632688000},{"_id":"themes/next/languages/en.yml","hash":"45bc5118828bdc72dcaa25282cd367c8622758cb","modified":1601632688000},{"_id":"themes/next/languages/fa.yml","hash":"3676b32fda37e122f3c1a655085a1868fb6ad66b","modified":1601632688000},{"_id":"themes/next/languages/id.yml","hash":"572ed855d47aafe26f58c73b1394530754881ec2","modified":1601632688000},{"_id":"themes/next/languages/hu.yml","hash":"b1ebb77a5fd101195b79f94de293bcf9001d996f","modified":1601632688000},{"_id":"themes/next/languages/ko.yml","hash":"0feea9e43cd399f3610b94d755a39fff1d371e97","modified":1601632688000},{"_id":"themes/next/languages/it.yml","hash":"44759f779ce9c260b895532de1d209ad4bd144bf","modified":1601632688000},{"_id":"themes/next/languages/ja.yml","hash":"0cf0baa663d530f22ff380a051881216d6adcdd8","modified":1601632688000},{"_id":"themes/next/languages/nl.yml","hash":"5af3473d9f22897204afabc08bb984b247493330","modified":1601632688000},{"_id":"themes/next/languages/pt.yml","hash":"718d131f42f214842337776e1eaddd1e9a584054","modified":1601632688000},{"_id":"themes/next/languages/ru.yml","hash":"e993d5ca072f7f6887e30fc0c19b4da791ca7a88","modified":1601632688000},{"_id":"themes/next/languages/pt-BR.yml","hash":"67555b1ba31a0242b12fc6ce3add28531160e35b","modified":1601632688000},{"_id":"themes/next/languages/tr.yml","hash":"fe793f4c2608e3f85f0b872fd0ac1fb93e6155e2","modified":1601632688000},{"_id":"themes/next/languages/uk.yml","hash":"3a6d635b1035423b22fc86d9455dba9003724de9","modified":1601632688000},{"_id":"themes/next/languages/zh-TW.yml","hash":"8c09da7c4ec3fca2c6ee897b2eea260596a2baa1","modified":1601632688000},{"_id":"themes/next/languages/vi.yml","hash":"93393b01df148dcbf0863f6eee8e404e2d94ef9e","modified":1601632688000},{"_id":"themes/next/languages/zh-CN.yml","hash":"a1f15571ee7e1e84e3cc0985c3ec4ba1a113f6f8","modified":1601632688000},{"_id":"themes/next/languages/zh-HK.yml","hash":"3789f94010f948e9f23e21235ef422a191753c65","modified":1601632688000},{"_id":"themes/next/layout/_layout.swig","hash":"6a6e92a4664cdb981890a27ac11fd057f44de1d5","modified":1601632688000},{"_id":"themes/next/layout/archive.swig","hash":"e4e31317a8df68f23156cfc49e9b1aa9a12ad2ed","modified":1601632688000},{"_id":"themes/next/layout/category.swig","hash":"1bde61cf4d2d171647311a0ac2c5c7933f6a53b0","modified":1601632688000},{"_id":"themes/next/layout/index.swig","hash":"7f403a18a68e6d662ae3e154b2c1d3bbe0801a23","modified":1601632688000},{"_id":"themes/next/layout/page.swig","hash":"db581bdeac5c75fabb0f17d7c5e746e47f2a9168","modified":1601632688000},{"_id":"themes/next/layout/post.swig","hash":"2f6d992ced7e067521fdce05ffe4fd75481f41c5","modified":1601632688000},{"_id":"themes/next/layout/tag.swig","hash":"0dfb653bd5de980426d55a0606d1ab122bd8c017","modified":1601632688000},{"_id":"themes/next/scripts/renderer.js","hash":"49a65df2028a1bc24814dc72fa50d52231ca4f05","modified":1601632688000},{"_id":"themes/next/.github/ISSUE_TEMPLATE/bug-report.md","hash":"c3e6b8196c983c40fd140bdeca012d03e6e86967","modified":1601632688000},{"_id":"themes/next/.github/ISSUE_TEMPLATE/other.md","hash":"d3efc0df0275c98440e69476f733097916a2d579","modified":1601632688000},{"_id":"themes/next/.github/ISSUE_TEMPLATE/feature-request.md","hash":"12d99fb8b62bd9e34d9672f306c9ae4ace7e053e","modified":1601632688000},{"_id":"themes/next/.github/ISSUE_TEMPLATE/question.md","hash":"53df7d537e26aaf062d70d86835c5fd8f81412f3","modified":1601632688000},{"_id":"themes/next/docs/ru/DATA-FILES.md","hash":"0bd2d696f62a997a11a7d84fec0130122234174e","modified":1601632688000},{"_id":"themes/next/docs/ru/INSTALLATION.md","hash":"9c4fe2873123bf9ceacab5c50d17d8a0f1baef27","modified":1601632688000},{"_id":"themes/next/docs/ru/UPDATE-FROM-5.1.X.md","hash":"5237a368ab99123749d724b6c379415f2c142a96","modified":1601632688000},{"_id":"themes/next/docs/ru/README.md","hash":"85dd68ed1250897a8e4a444a53a68c1d49eb7e11","modified":1601632688000},{"_id":"themes/next/docs/zh-CN/ALGOLIA-SEARCH.md","hash":"34b88784ec120dfdc20fa82aadeb5f64ef614d14","modified":1601632688000},{"_id":"themes/next/docs/zh-CN/CODE_OF_CONDUCT.md","hash":"fb23b85db6f7d8279d73ae1f41631f92f64fc864","modified":1601632688000},{"_id":"themes/next/docs/zh-CN/CONTRIBUTING.md","hash":"d3f03be036b75dc71cf3c366cd75aee7c127c874","modified":1601632688000},{"_id":"themes/next/docs/zh-CN/DATA-FILES.md","hash":"ca1030efdfca5e20f9db2e7a428998e66a24c0d0","modified":1601632688000},{"_id":"themes/next/docs/zh-CN/MATH.md","hash":"b92585d251f1f9ebe401abb5d932cb920f9b8b10","modified":1601632688000},{"_id":"themes/next/docs/zh-CN/INSTALLATION.md","hash":"579c7bd8341873fb8be4732476d412814f1a3df7","modified":1601632688000},{"_id":"themes/next/docs/zh-CN/LEANCLOUD-COUNTER-SECURITY.md","hash":"8b18f84503a361fc712b0fe4d4568e2f086ca97d","modified":1601632688000},{"_id":"themes/next/docs/zh-CN/README.md","hash":"c038629ff8f3f24e8593c4c8ecf0bef3a35c750d","modified":1601632688000},{"_id":"themes/next/docs/zh-CN/UPDATE-FROM-5.1.X.md","hash":"d9ce7331c1236bbe0a551d56cef2405e47e65325","modified":1601632688000},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"71655ca21907e9061b6e8ac52d0d8fbf54d0062b","modified":1601632688000},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"9c8dc0b8170679cdc1ee9ee8dbcbaebf3f42897b","modified":1601632688000},{"_id":"themes/next/layout/_macro/post.swig","hash":"090b5a9b6fca8e968178004cbd6cff205b7eba57","modified":1601632688000},{"_id":"themes/next/layout/_partials/comments.swig","hash":"db6ab5421b5f4b7cb32ac73ad0e053fdf065f83e","modified":1601632688000},{"_id":"themes/next/layout/_partials/footer.swig","hash":"75882c0a9fd3e66b8d62f9212e8246e4da92fc79","modified":1601869549489},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9876dbfc15713c7a47d4bcaa301f4757bd978269","modified":1601632688000},{"_id":"themes/next/layout/_partials/languages.swig","hash":"ba9e272f1065b8f0e8848648caa7dea3f02c6be1","modified":1601632688000},{"_id":"themes/next/layout/_partials/widgets.swig","hash":"83a40ce83dfd5cada417444fb2d6f5470aae6bb0","modified":1601632688000},{"_id":"themes/next/layout/_scripts/noscript.swig","hash":"d1f2bfde6f1da51a2b35a7ab9e7e8eb6eefd1c6b","modified":1601632688000},{"_id":"themes/next/layout/_scripts/index.swig","hash":"cea942b450bcb0f352da78d76dc6d6f1d23d5029","modified":1601632688000},{"_id":"themes/next/layout/_scripts/pjax.swig","hash":"4d2c93c66e069852bb0e3ea2e268d213d07bfa3f","modified":1601632688000},{"_id":"themes/next/layout/_scripts/three.swig","hash":"a4f42f2301866bd25a784a2281069d8b66836d0b","modified":1601632688000},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"ef38c213679e7b6d2a4116f56c9e55d678446069","modified":1601632688000},{"_id":"themes/next/layout/_third-party/baidu-push.swig","hash":"b782eb2e34c0c15440837040b5d65b093ab6ec04","modified":1601632688000},{"_id":"themes/next/layout/_third-party/index.swig","hash":"70c3c01dd181de81270c57f3d99b6d8f4c723404","modified":1601632688000},{"_id":"themes/next/layout/_third-party/quicklink.swig","hash":"311e5eceec9e949f1ea8d623b083cec0b8700ff2","modified":1601632688000},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"2731e262a6b88eaee2a3ca61e6a3583a7f594702","modified":1601632688000},{"_id":"themes/next/scripts/events/index.js","hash":"5743cde07f3d2aa11532a168a652e52ec28514fd","modified":1601632688000},{"_id":"themes/next/scripts/filters/default-injects.js","hash":"aec50ed57b9d5d3faf2db3c88374f107203617e0","modified":1601632688000},{"_id":"themes/next/scripts/filters/locals.js","hash":"b193a936ee63451f09f8886343dcfdca577c0141","modified":1601632688000},{"_id":"themes/next/scripts/filters/minify.js","hash":"19985723b9f677ff775f3b17dcebf314819a76ac","modified":1601632688000},{"_id":"themes/next/scripts/filters/front-matter.js","hash":"703bdd142a671b4b67d3d9dfb4a19d1dd7e7e8f7","modified":1601632688000},{"_id":"themes/next/scripts/filters/post.js","hash":"44ba9b1c0bdda57590b53141306bb90adf0678db","modified":1601632688000},{"_id":"themes/next/scripts/helpers/engine.js","hash":"bdb424c3cc0d145bd0c6015bb1d2443c8a9c6cda","modified":1601632688000},{"_id":"themes/next/scripts/helpers/next-config.js","hash":"5e11f30ddb5093a88a687446617a46b048fa02e5","modified":1601632688000},{"_id":"themes/next/scripts/helpers/next-url.js","hash":"958e86b2bd24e4fdfcbf9ce73e998efe3491a71f","modified":1601632688000},{"_id":"themes/next/scripts/helpers/font.js","hash":"40cf00e9f2b7aa6e5f33d412e03ed10304b15fd7","modified":1601632688000},{"_id":"themes/next/scripts/tags/button.js","hash":"8c6b45f36e324820c919a822674703769e6da32c","modified":1601632688000},{"_id":"themes/next/scripts/tags/caniuse.js","hash":"94e0bbc7999b359baa42fa3731bdcf89c79ae2b3","modified":1601632688000},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"f1826ade2d135e2f60e2d95cb035383685b3370c","modified":1601632688000},{"_id":"themes/next/scripts/tags/label.js","hash":"fc5b267d903facb7a35001792db28b801cccb1f8","modified":1601632688000},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"d902fd313e8d35c3cc36f237607c2a0536c9edf1","modified":1601632688000},{"_id":"themes/next/scripts/tags/mermaid.js","hash":"983c6c4adea86160ecc0ba2204bc312aa338121d","modified":1601632688000},{"_id":"themes/next/scripts/tags/note.js","hash":"0a02bb4c15aec41f6d5f1271cdb5c65889e265d9","modified":1601632688000},{"_id":"themes/next/scripts/tags/pdf.js","hash":"8c613b39e7bff735473e35244b5629d02ee20618","modified":1601632688000},{"_id":"themes/next/scripts/tags/video.js","hash":"e5ff4c44faee604dd3ea9db6b222828c4750c227","modified":1601632688000},{"_id":"themes/next/scripts/tags/tabs.js","hash":"93d8a734a3035c1d3f04933167b500517557ba3e","modified":1601632688000},{"_id":"themes/next/source/css/_colors.styl","hash":"a8442520f719d3d7a19811cb3b85bcfd4a596e1f","modified":1601632688000},{"_id":"themes/next/source/css/_mixins.styl","hash":"e31a557f8879c2f4d8d5567ee1800b3e03f91f6e","modified":1601632688000},{"_id":"themes/next/source/css/main.styl","hash":"a3a3bbb5a973052f0186b3523911cb2539ff7b88","modified":1601632688000},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1601632688000},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1601632688000},{"_id":"themes/next/source/images/avatar.gif","hash":"18c53e15eb0c84b139995f9334ed8522b40aeaf6","modified":1601632688000},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1601632688000},{"_id":"themes/next/source/images/avatar.jpg","hash":"1fb6da2bfc227d6088f124d8fafb6a098900bcdf","modified":1601643128000},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1601632688000},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1601632688000},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1601632688000},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1601632688000},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1601632688000},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1601632688000},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1601632688000},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1601632688000},{"_id":"themes/next/source/js/algolia-search.js","hash":"498d233eb5c7af6940baf94c1a1c36fdf1dd2636","modified":1601632688000},{"_id":"themes/next/source/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1601632688000},{"_id":"themes/next/source/js/bookmark.js","hash":"9734ebcb9b83489686f5c2da67dc9e6157e988ad","modified":1601632688000},{"_id":"themes/next/source/js/local-search.js","hash":"35ccf100d8f9c0fd6bfbb7fa88c2a76c42a69110","modified":1601632688000},{"_id":"themes/next/source/js/motion.js","hash":"72df86f6dfa29cce22abeff9d814c9dddfcf13a9","modified":1601632688000},{"_id":"themes/next/layout/_partials/head/head.swig","hash":"810d544019e4a8651b756dd23e5592ee851eda71","modified":1601632688000},{"_id":"themes/next/layout/_partials/header/brand.swig","hash":"c70f8e71e026e878a4e9d5ab3bbbf9b0b23c240c","modified":1601632688000},{"_id":"themes/next/layout/_partials/head/head-unique.swig","hash":"000bad572d76ee95d9c0a78f9ccdc8d97cc7d4b4","modified":1601632688000},{"_id":"themes/next/source/js/next-boot.js","hash":"a1b0636423009d4a4e4cea97bcbf1842bfab582c","modified":1601632688000},{"_id":"themes/next/layout/_partials/header/index.swig","hash":"7dbe93b8297b746afb89700b4d29289556e85267","modified":1601632688000},{"_id":"themes/next/layout/_partials/header/menu-item.swig","hash":"9440d8a3a181698b80e1fa47f5104f4565d8cdf3","modified":1601632688000},{"_id":"themes/next/layout/_partials/header/sub-menu.swig","hash":"ae2261bea836581918a1c2b0d1028a78718434e0","modified":1601632688000},{"_id":"themes/next/layout/_partials/header/menu.swig","hash":"d31f896680a6c2f2c3f5128b4d4dd46c87ce2130","modified":1601632688000},{"_id":"themes/next/layout/_partials/page/breadcrumb.swig","hash":"c851717497ca64789f2176c9ecd1dedab237b752","modified":1601632688000},{"_id":"themes/next/layout/_partials/post/post-copyright.swig","hash":"954ad71536b6eb08bd1f30ac6e2f5493b69d1c04","modified":1601632688000},{"_id":"themes/next/layout/_partials/page/page-header.swig","hash":"9b7a66791d7822c52117fe167612265356512477","modified":1601632688000},{"_id":"themes/next/source/lib/anime.min.js","hash":"47cb482a8a488620a793d50ba8f6752324b46af3","modified":1601632688000},{"_id":"themes/next/source/js/utils.js","hash":"730cca7f164eaf258661a61ff3f769851ff1e5da","modified":1601632688000},{"_id":"themes/next/layout/_partials/post/post-followme.swig","hash":"ceba16b9bd3a0c5c8811af7e7e49d0f9dcb2f41e","modified":1601632688000},{"_id":"themes/next/layout/_partials/post/post-footer.swig","hash":"8f14f3f8a1b2998d5114cc56b680fb5c419a6b07","modified":1601632688000},{"_id":"themes/next/layout/_partials/search/algolia-search.swig","hash":"48430bd03b8f19c9b8cdb2642005ed67d56c6e0b","modified":1601632688000},{"_id":"themes/next/layout/_partials/post/post-related.swig","hash":"f79c44692451db26efce704813f7a8872b7e63a0","modified":1601632688000},{"_id":"themes/next/layout/_partials/search/index.swig","hash":"2be50f9bfb1c56b85b3b6910a7df27f51143632c","modified":1601632688000},{"_id":"themes/next/layout/_partials/post/post-reward.swig","hash":"2b1a73556595c37951e39574df5a3f20b2edeaef","modified":1601632688000},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"f48a6a8eba04eb962470ce76dd731e13074d4c45","modified":1601632688000},{"_id":"themes/next/layout/_partials/sidebar/site-overview.swig","hash":"c46849e0af8f8fb78baccd40d2af14df04a074af","modified":1601632688000},{"_id":"themes/next/layout/_scripts/pages/schedule.swig","hash":"077b5d66f6309f2e7dcf08645058ff2e03143e6c","modified":1601632688000},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"7f14ef43d9e82bc1efc204c5adf0b1dbfc919a9f","modified":1601632688000},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"1c910fc066c06d5fbbe9f2b0c47447539e029af7","modified":1601632688000},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"1c910fc066c06d5fbbe9f2b0c47447539e029af7","modified":1601632688000},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"7f14ef43d9e82bc1efc204c5adf0b1dbfc919a9f","modified":1601632688000},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"4790058691b7d36cf6d2d6b4e93795a7b8d608ad","modified":1601632688000},{"_id":"themes/next/layout/_third-party/chat/chatra.swig","hash":"f910618292c63871ca2e6c6e66c491f344fa7b1f","modified":1601632688000},{"_id":"themes/next/layout/_third-party/analytics/growingio.swig","hash":"5adea065641e8c55994dd2328ddae53215604928","modified":1601632688000},{"_id":"themes/next/layout/_third-party/chat/tidio.swig","hash":"cba0e6e0fad08568a9e74ba9a5bee5341cfc04c1","modified":1601632688000},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"f39a5bf3ce9ee9adad282501235e0c588e4356ec","modified":1601632688000},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"b14908644225d78c864cd0a9b60c52407de56183","modified":1601632688000},{"_id":"themes/next/layout/_third-party/comments/disqusjs.swig","hash":"82f5b6822aa5ec958aa987b101ef860494c6cf1f","modified":1601632688000},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"1472cabb0181f60a6a0b7fec8899a4d03dfb2040","modified":1601632688000},{"_id":"themes/next/layout/_third-party/comments/gitalk.swig","hash":"d6ceb70648555338a80ae5724b778c8c58d7060d","modified":1601632688000},{"_id":"themes/next/layout/_third-party/math/index.swig","hash":"6c5976621efd5db5f7c4c6b4f11bc79d6554885f","modified":1601632688000},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"f7a9eca599a682479e8ca863db59be7c9c7508c8","modified":1601632688000},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"be0a8eccf1f6dc21154af297fc79555343031277","modified":1601632688000},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"2fa2b51d56bfac6a1ea76d651c93b9c20b01c09b","modified":1601632688000},{"_id":"themes/next/layout/_third-party/math/mathjax.swig","hash":"ecf751321e799f0fb3bf94d049e535130e2547aa","modified":1601632688000},{"_id":"themes/next/layout/_third-party/search/algolia-search.swig","hash":"d35a999d67f4c302f76fdf13744ceef3c6506481","modified":1601632688000},{"_id":"themes/next/layout/_third-party/math/katex.swig","hash":"4791c977a730f29c846efcf6c9c15131b9400ead","modified":1601632688000},{"_id":"themes/next/layout/_third-party/search/swiftype.swig","hash":"ba0dbc06b9d244073a1c681ff7a722dcbf920b51","modified":1601632688000},{"_id":"themes/next/layout/_third-party/statistics/busuanzi-counter.swig","hash":"4b1986e43d6abce13450d2b41a736dd6a5620a10","modified":1601632688000},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"767b6c714c22588bcd26ba70b0fc19b6810cbacd","modified":1601632688000},{"_id":"themes/next/layout/_third-party/statistics/cnzz-analytics.swig","hash":"a17ace37876822327a2f9306a472974442c9005d","modified":1601632688000},{"_id":"themes/next/layout/_third-party/statistics/firestore.swig","hash":"b26ac2bfbe91dd88267f8b96aee6bb222b265b7a","modified":1601632688000},{"_id":"themes/next/layout/_third-party/statistics/lean-analytics.swig","hash":"d56d5af427cdfecc33a0f62ee62c056b4e33d095","modified":1601632688000},{"_id":"themes/next/layout/_third-party/tags/pdf.swig","hash":"d30b0e255a8092043bac46441243f943ed6fb09b","modified":1601632688000},{"_id":"themes/next/layout/_third-party/tags/mermaid.swig","hash":"f3c43664a071ff3c0b28bd7e59b5523446829576","modified":1601632688000},{"_id":"themes/next/layout/_third-party/statistics/index.swig","hash":"5f6a966c509680dbfa70433f9d658cee59c304d7","modified":1601632688000},{"_id":"themes/next/scripts/events/lib/injects-point.js","hash":"6661c1c91c7cbdefc6a5e6a034b443b8811235a1","modified":1601632688000},{"_id":"themes/next/scripts/events/lib/config.js","hash":"d34c6040b13649714939f59be5175e137de65ede","modified":1601632688000},{"_id":"themes/next/scripts/events/lib/injects.js","hash":"f233d8d0103ae7f9b861344aa65c1a3c1de8a845","modified":1601632688000},{"_id":"themes/next/scripts/filters/comment/common.js","hash":"2486f3e0150c753e5f3af1a3665d074704b8ee2c","modified":1601632688000},{"_id":"themes/next/scripts/filters/comment/changyan.js","hash":"a54708fd9309b4357c423a3730eb67f395344a5e","modified":1601632688000},{"_id":"themes/next/scripts/filters/comment/default-config.js","hash":"7f2d93af012c1e14b8596fecbfc7febb43d9b7f5","modified":1601632688000},{"_id":"themes/next/scripts/filters/comment/disqus.js","hash":"4c0c99c7e0f00849003dfce02a131104fb671137","modified":1601632688000},{"_id":"themes/next/scripts/filters/comment/disqusjs.js","hash":"7f8b92913d21070b489457fa5ed996d2a55f2c32","modified":1601632688000},{"_id":"themes/next/scripts/filters/comment/gitalk.js","hash":"e51dc3072c1ba0ea3008f09ecae8b46242ec6021","modified":1601632688000},{"_id":"themes/next/scripts/filters/comment/livere.js","hash":"d5fefc31fba4ab0188305b1af1feb61da49fdeb0","modified":1601632688000},{"_id":"themes/next/scripts/filters/comment/valine.js","hash":"6cbd85f9433c06bae22225ccf75ac55e04f2d106","modified":1601632688000},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"f70be8e229da7e1715c11dd0e975a2e71e453ac8","modified":1601632688000},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"f4e694e5db81e57442c7e34505a416d818b3044a","modified":1601632688000},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"612ec843372dae709acb17112c1145a53450cc59","modified":1601632688000},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"62df49459d552bbf73841753da8011a1f5e875c8","modified":1601632688000},{"_id":"themes/next/source/js/schemes/muse.js","hash":"1eb9b88103ddcf8827b1a7cbc56471a9c5592d53","modified":1601632688000},{"_id":"themes/next/source/css/_variables/base.styl","hash":"818508748b7a62e02035e87fe58e75b603ed56dc","modified":1601632688000},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"ca5e70662dcfb261c25191cc5db5084dcf661c76","modified":1601632688000},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"a47725574e1bee3bc3b63b0ff2039cc982b17eff","modified":1601632688000},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"8e7b57a72e757cf95278239641726bb2d5b869d1","modified":1601632688000},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"0b2c4b78eead410020d7c4ded59c75592a648df8","modified":1601632688000},{"_id":"themes/next/source/css/_common/components/reading-progress.styl","hash":"2e3bf7baf383c9073ec5e67f157d3cb3823c0957","modified":1601632688000},{"_id":"themes/next/source/js/schemes/pisces.js","hash":"0ac5ce155bc58c972fe21c4c447f85e6f8755c62","modified":1601632688000},{"_id":"themes/next/source/css/_common/scaffolding/buttons.styl","hash":"a2e9e00962e43e98ec2614d6d248ef1773bb9b78","modified":1601632688000},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1601632688000},{"_id":"themes/next/source/css/_common/scaffolding/comments.styl","hash":"b1f0fab7344a20ed6748b04065b141ad423cf4d9","modified":1601632688000},{"_id":"themes/next/source/css/_common/scaffolding/pagination.styl","hash":"8f58570a1bbc34c4989a47a1b7d42a8030f38b06","modified":1601632688000},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"b56367ea676ea8e8783ea89cd4ab150c7da7a060","modified":1601632688000},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1601632688000},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"523fb7b653b87ae37fc91fc8813e4ffad87b0d7e","modified":1601632688000},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"18ce72d90459c9aa66910ac64eae115f2dde3767","modified":1601632688000},{"_id":"themes/next/source/css/_common/outline/mobile.styl","hash":"681d33e3bc85bdca407d93b134c089264837378c","modified":1601632688000},{"_id":"themes/next/source/css/_common/scaffolding/toggles.styl","hash":"179e33b8ac7f4d8a8e76736a7e4f965fe9ab8b42","modified":1601632688000},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"a1690e035b505d28bdef2b4424c13fc6312ab049","modified":1601632688000},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"7785bd756e0c4acede3a47fec1ed7b55988385a5","modified":1601632688000},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"f6516d0f7d89dc7b6c6e143a5af54b926f585d82","modified":1601632688000},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expand.styl","hash":"6136da4bbb7e70cec99f5c7ae8c7e74f5e7c261a","modified":1601632688000},{"_id":"themes/next/source/css/_schemes/Mist/_layout.styl","hash":"bb7ace23345364eb14983e860a7172e1683a4c94","modified":1601632688000},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"7104b9cef90ca3b140d7a7afcf15540a250218fc","modified":1601632688000},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"a717969829fa6ef88225095737df3f8ee86c286b","modified":1601632688000},{"_id":"themes/next/source/css/_schemes/Muse/_header.styl","hash":"f0131db6275ceaecae7e1a6a3798b8f89f6c850d","modified":1601632688000},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"93db5dafe9294542a6b5f647643cb9deaced8e06","modified":1601632688000},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"4d1c17345d2d39ef7698f7acf82dfc0f59308c34","modified":1601632688000},{"_id":"themes/next/source/css/_schemes/Muse/_sidebar.styl","hash":"2b2e7b5cea7783c9c8bb92655e26a67c266886f0","modified":1601632688000},{"_id":"themes/next/source/css/_schemes/Muse/_sub-menu.styl","hash":"c48ccd8d6651fe1a01faff8f01179456d39ba9b1","modified":1601632688000},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"6ad168288b213cec357e9b5a97674ff2ef3a910c","modified":1601632688000},{"_id":"themes/next/source/css/_schemes/Pisces/_header.styl","hash":"e282df938bd029f391c466168d0e68389978f120","modified":1601632688000},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"70a4324b70501132855b5e59029acfc5d3da1ebd","modified":1601632688000},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"85da2f3006f4bef9a2199416ecfab4d288f848c4","modified":1601632688000},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"6ad168288b213cec357e9b5a97674ff2ef3a910c","modified":1601632688000},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"44f47c88c06d89d06f220f102649057118715828","modified":1601632688000},{"_id":"themes/next/source/css/_schemes/Pisces/_sub-menu.styl","hash":"e740deadcfc4f29c5cb01e40f9df6277262ba4e3","modified":1601632688000},{"_id":"themes/next/source/lib/font-awesome/css/all.min.css","hash":"0038dc97c79451578b7bd48af60ba62282b4082b","modified":1601632688000},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-regular-400.woff2","hash":"260bb01acd44d88dcb7f501a238ab968f86bef9e","modified":1601632688000},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"2bd0eb1512415325653b26d62a4463e6de83c5ac","modified":1601632688000},{"_id":"themes/next/source/css/_common/components/pages/breadcrumb.styl","hash":"fafc96c86926b22afba8bb9418c05e6afbc05a57","modified":1601632688000},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"7504dbc5c70262b048143b2c37d2b5aa2809afa2","modified":1601632688000},{"_id":"themes/next/source/css/_common/components/pages/tag-cloud.styl","hash":"d21d4ac1982c13d02f125a67c065412085a92ff2","modified":1601632688000},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"e75693f33dbc92afc55489438267869ae2f3db54","modified":1601632688000},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"e771dcb0b4673e063c0f3e2d73e7336ac05bcd57","modified":1601632688000},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"eadf4ff9bb759718ccab432aa862b66dfd122bdb","modified":1601877066728},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"902569a9dea90548bec21a823dd3efd94ff7c133","modified":1601632688000},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"ded41fd9d20a5e8db66aaff7cc50f105f5ef2952","modified":1601632688000},{"_id":"themes/next/source/css/_common/components/post/post-followme.styl","hash":"1e4190c10c9e0c9ce92653b0dbcec21754b0b69d","modified":1601632688000},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"72d495a88f7d6515af425c12cbc67308a57d88ea","modified":1601632688000},{"_id":"themes/next/source/css/_common/components/post/post-header.styl","hash":"65cb6edb69e94e70e3291e9132408361148d41d5","modified":1601632688000},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"d114b2a531129e739a27ba6271cfe6857aa9a865","modified":1601632688000},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"6a97bcfa635d637dc59005be3b931109e0d1ead5","modified":1601632688000},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"99e12c9ce3d14d4837e3d3f12fc867ba9c565317","modified":1601632688000},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"f5c2788a78790aca1a2f37f7149d6058afb539e0","modified":1601632688000},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"5b5649b9749e3fd8b63aef22ceeece0a6e1df605","modified":1601632688000},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"a760ee83ba6216871a9f14c5e56dc9bd0d9e2103","modified":1601632688000},{"_id":"themes/next/source/css/_common/components/third-party/gitalk.styl","hash":"8a7fc03a568b95be8d3337195e38bc7ec5ba2b23","modified":1601632688000},{"_id":"themes/next/source/css/_common/components/third-party/math.styl","hash":"b49e9fbd3c182b8fc066b8c2caf248e3eb748619","modified":1601632688000},{"_id":"themes/next/source/css/_common/components/third-party/related-posts.styl","hash":"e2992846b39bf3857b5104675af02ba73e72eed5","modified":1601632688000},{"_id":"themes/next/source/css/_common/components/third-party/search.styl","hash":"9f0b93d109c9aec79450c8a0cf4a4eab717d674d","modified":1601632688000},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"9a878d0119785a2316f42aebcceaa05a120b9a7a","modified":1601632688000},{"_id":"themes/next/source/css/_common/scaffolding/highlight/copy-code.styl","hash":"f71a3e86c05ea668b008cf05a81f67d92b6d65e4","modified":1601632688000},{"_id":"themes/next/source/css/_common/scaffolding/highlight/diff.styl","hash":"d3f73688bb7423e3ab0de1efdf6db46db5e34f80","modified":1601632688000},{"_id":"themes/next/source/css/_common/scaffolding/highlight/highlight.styl","hash":"35c871a809afa8306c8cde13651010e282548bc6","modified":1601632688000},{"_id":"themes/next/source/css/_common/scaffolding/highlight/theme.styl","hash":"3b3acc5caa0b95a2598bef4eeacb21bab21bea56","modified":1601632688000},{"_id":"themes/next/source/css/_common/scaffolding/tags/blockquote-center.styl","hash":"1d2778ca5aeeeafaa690dc2766b01b352ab76a02","modified":1601632688000},{"_id":"themes/next/source/css/_common/scaffolding/tags/label.styl","hash":"d7fce4b51b5f4b7c31d93a9edb6c6ce740aa0d6b","modified":1601632688000},{"_id":"themes/next/source/css/_common/scaffolding/tags/group-pictures.styl","hash":"709d10f763e357e1472d6471f8be384ec9e2d983","modified":1601632688000},{"_id":"themes/next/source/css/_common/scaffolding/tags/note.styl","hash":"e4d9a77ffe98e851c1202676940097ba28253313","modified":1601632688000},{"_id":"themes/next/source/css/_common/scaffolding/tags/tabs.styl","hash":"f23670f1d8e749f3e83766d446790d8fd9620278","modified":1601632688000},{"_id":"themes/next/source/css/_common/scaffolding/tags/pdf.styl","hash":"b49c64f8e9a6ca1c45c0ba98febf1974fdd03616","modified":1601632688000},{"_id":"themes/next/source/css/_common/outline/footer/footer.styl","hash":"454a4aebfabb4469b92a8cbb49f46c49ac9bf165","modified":1601632688000},{"_id":"themes/next/source/css/_common/scaffolding/tags/tags.styl","hash":"9e4c0653cfd3cc6908fa0d97581bcf80861fb1e7","modified":1601632688000},{"_id":"themes/next/source/css/_common/outline/header/bookmark.styl","hash":"e2d606f1ac343e9be4f15dbbaf3464bc4df8bf81","modified":1601632688000},{"_id":"themes/next/source/css/_common/outline/header/github-banner.styl","hash":"e7a9fdb6478b8674b1cdf94de4f8052843fb71d9","modified":1601632688000},{"_id":"themes/next/source/css/_common/outline/header/header.styl","hash":"a793cfff86ad4af818faef04c18013077873f8f0","modified":1601632688000},{"_id":"themes/next/source/css/_common/outline/header/headerband.styl","hash":"0caf32492692ba8e854da43697a2ec8a41612194","modified":1601632688000},{"_id":"themes/next/source/css/_common/outline/header/menu.styl","hash":"5f432a6ed9ca80a413c68b00e93d4a411abf280a","modified":1601632688000},{"_id":"themes/next/source/css/_common/outline/header/site-nav.styl","hash":"b2fc519828fe89a1f8f03ff7b809ad68cd46f3d7","modified":1601632688000},{"_id":"themes/next/source/css/_common/outline/header/site-meta.styl","hash":"45a239edca44acecf971d99b04f30a1aafbf6906","modified":1601632688000},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-author-links.styl","hash":"2cb1876e9e0c9ac32160888af27b1178dbcb0616","modified":1601632688000},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-author.styl","hash":"fa0222197b5eee47e18ac864cdc6eac75678b8fe","modified":1601632688000},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-button.styl","hash":"1f0e7fbe80956f47087c2458ea880acf7a83078b","modified":1601632688000},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-blogroll.styl","hash":"44487d9ab290dc97871fa8dd4487016deb56e123","modified":1601632688000},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-nav.styl","hash":"a960a2dd587b15d3b3fe1b59525d6fa971c6a6ec","modified":1601632688000},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-toggle.styl","hash":"b3220db827e1adbca7880c2bb23e78fa7cbe95cb","modified":1601632688000},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-dimmer.styl","hash":"9b479c2f9a9bfed77885e5093b8245cc5d768ec7","modified":1601632688000},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-toc.styl","hash":"a05a4031e799bc864a4536f9ef61fe643cd421af","modified":1601632688000},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar.styl","hash":"a9cd93c36bae5af9223e7804963096274e8a4f03","modified":1601632688000},{"_id":"themes/next/source/css/_common/outline/sidebar/site-state.styl","hash":"2a47f8a6bb589c2fb635e6c1e4a2563c7f63c407","modified":1601632688000},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-brands-400.woff2","hash":"509988477da79c146cb93fb728405f18e923c2de","modified":1601632688000},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-solid-900.woff2","hash":"75a88815c47a249eadb5f0edc1675957f860cca7","modified":1601632688000},{"_id":"source/_posts/2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances/WMDPaper.png","hash":"3002705f5381d01a32819cb67c27e73fe49a8b45","modified":1635866221931},{"_id":"source/_posts/2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances/cvxoptRep.jpg","hash":"487c2efc64aa06a7c223c1081f67ecd80037a1a6","modified":1635866221945},{"_id":"public/about/index.html","hash":"908930d2940fd8353c41ebb9bba3c0e69dc15f69","modified":1635866526218},{"_id":"public/categories/index.html","hash":"77f065619cc4dcf8087480fe87f03569a4410e6f","modified":1635866526218},{"_id":"public/tags/index.html","hash":"67b7946369faac21ebe7867c30a88ea15a0dc847","modified":1635866526218},{"_id":"public/archives/index.html","hash":"ebb1ee346a04dbf2ffee2c5c28f44a5ac06672da","modified":1635866526218},{"_id":"public/archives/2020/index.html","hash":"e42078537fdc14003a57044662451f2b9ca69222","modified":1635866526218},{"_id":"public/archives/2020/10/index.html","hash":"86e6b6b63efaf9e49da779c165c10daae6493565","modified":1635866526218},{"_id":"public/categories/nlp/index.html","hash":"1c9126f5fe5e01732ea8e4b57e132435e8a02aeb","modified":1635866526218},{"_id":"public/2020/10/03/8321bff9.html","hash":"1804f29887c6efc80a08cd2b0d80e36686d933d9","modified":1635866526218},{"_id":"public/index.html","hash":"5471338ce77701b765df0b4db3e71d90b5d5fe47","modified":1635866526218},{"_id":"public/tags/paper/index.html","hash":"d441967d4ee6c2d0f2d4d3b96d114149c08905b6","modified":1635866526218},{"_id":"public/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1635866526218},{"_id":"public/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1635866526218},{"_id":"public/images/avatar.gif","hash":"18c53e15eb0c84b139995f9334ed8522b40aeaf6","modified":1635866526218},{"_id":"public/images/avatar.jpg","hash":"1fb6da2bfc227d6088f124d8fafb6a098900bcdf","modified":1635866526218},{"_id":"public/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1635866526218},{"_id":"public/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1635866526218},{"_id":"public/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1635866526218},{"_id":"public/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1635866526218},{"_id":"public/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1635866526218},{"_id":"public/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1635866526218},{"_id":"public/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1635866526218},{"_id":"public/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1635866526218},{"_id":"public/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1635866526218},{"_id":"public/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1635866526218},{"_id":"public/lib/font-awesome/webfonts/fa-regular-400.woff2","hash":"260bb01acd44d88dcb7f501a238ab968f86bef9e","modified":1635866526218},{"_id":"public/2020/10/03/8321bff9/dataset.png","hash":"6ad2540bc3265bb799540716added607ddd21655","modified":1635866526218},{"_id":"public/2020/10/03/8321bff9/docRep.jpg","hash":"c82e5f9da1401a5c03183aa586ba7932a76664a5","modified":1635866526218},{"_id":"public/2020/10/03/8321bff9/nBow.jpg","hash":"3008125376aed439f0c85c842c6c1c26107c518c","modified":1635866526218},{"_id":"public/2020/10/03/8321bff9/visualization.png","hash":"e5d00f714514ca2969a29c29facbe5d2e1c0a73d","modified":1635866526218},{"_id":"public/lib/font-awesome/webfonts/fa-brands-400.woff2","hash":"509988477da79c146cb93fb728405f18e923c2de","modified":1635866526218},{"_id":"public/lib/font-awesome/webfonts/fa-solid-900.woff2","hash":"75a88815c47a249eadb5f0edc1675957f860cca7","modified":1635866526218},{"_id":"public/2020/10/03/8321bff9/prefetch.png","hash":"b597f2e674dd5729835d210c5b47297b773b0176","modified":1635866526218},{"_id":"public/js/algolia-search.js","hash":"498d233eb5c7af6940baf94c1a1c36fdf1dd2636","modified":1635866526218},{"_id":"public/js/bookmark.js","hash":"9734ebcb9b83489686f5c2da67dc9e6157e988ad","modified":1635866526218},{"_id":"public/js/local-search.js","hash":"35ccf100d8f9c0fd6bfbb7fa88c2a76c42a69110","modified":1635866526218},{"_id":"public/js/next-boot.js","hash":"a1b0636423009d4a4e4cea97bcbf1842bfab582c","modified":1635866526218},{"_id":"public/js/utils.js","hash":"730cca7f164eaf258661a61ff3f769851ff1e5da","modified":1635866526218},{"_id":"public/js/schemes/muse.js","hash":"1eb9b88103ddcf8827b1a7cbc56471a9c5592d53","modified":1635866526218},{"_id":"public/js/motion.js","hash":"72df86f6dfa29cce22abeff9d814c9dddfcf13a9","modified":1635866526218},{"_id":"public/js/schemes/pisces.js","hash":"0ac5ce155bc58c972fe21c4c447f85e6f8755c62","modified":1635866526218},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1635866526218},{"_id":"public/css/main.css","hash":"3ed05ede55fc2fd129ac686720dcf140549852c6","modified":1635866526218},{"_id":"public/lib/anime.min.js","hash":"47cb482a8a488620a793d50ba8f6752324b46af3","modified":1635866526218},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1635866526218},{"_id":"public/lib/font-awesome/css/all.min.css","hash":"0038dc97c79451578b7bd48af60ba62282b4082b","modified":1635866526218},{"_id":"public/2020/10/03/8321bff9/WMDPaper.png","hash":"3002705f5381d01a32819cb67c27e73fe49a8b45","modified":1635866526218},{"_id":"public/2020/10/03/8321bff9/cvxoptRep.jpg","hash":"487c2efc64aa06a7c223c1081f67ecd80037a1a6","modified":1635866526218}],"Category":[{"name":"nlp","_id":"ckvi8p0ac0004ggsjft095716"}],"Data":[],"Page":[{"title":"这个人很懒 什么都没留下","date":"2020-10-05T06:14:13.000Z","_content":"","source":"about/index.md","raw":"---\ntitle: 这个人很懒 什么都没留下\ndate: 2020-10-05 14:14:13\n---\n","updated":"2021-11-02T15:17:01.967Z","path":"about/index.html","comments":1,"layout":"page","_id":"ckvi8p0a00000ggsjehpc1m9y","content":"","site":{"data":{}},"excerpt":"","more":""},{"date":"2020-10-05T06:08:35.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ndate: 2020-10-05 14:08:35\ntype: \"categories\"\n---\n","updated":"2021-11-02T15:17:01.970Z","path":"categories/index.html","title":"","comments":1,"layout":"page","_id":"ckvi8p0a40001ggsj4tqv4kap","content":"","site":{"data":{}},"excerpt":"","more":""},{"date":"2020-10-05T06:12:11.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ndate: 2020-10-05 14:12:11\ntype: \"tags\"\n---\n","updated":"2021-11-02T15:17:01.972Z","path":"tags/index.html","title":"","comments":1,"layout":"page","_id":"ckvi8p0a60002ggsjd84985vj","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"WMD论文详解及代码介绍:From_Word_Embeddings_to_Document_Distances","abbrlink":"8321bff9","date":"2020-10-03T05:37:10.000Z","mathjax":true,"_content":"&emsp;&emsp;本文对《From Word Embeddings to Document Distances》论文（以下简称“WMD论文”）进行了讲解，并对其代码实现进行了介绍。  \n\n## 1. 论文讲解\n&emsp;&emsp;在WMD论文中，作者提出了Word Mover's Distance算法用来计算文档之间的距离，该算法基于word embedding来表示句子中的词向量。同时作者将文本距离计算问题看作是the Earth Mover's Distance问题的一个实例，并提出了多种计算优化方法。以下是整个论文的框架，以及对WMD及其计算优化的详细讲解。\n<!--more-->  \n\n### 1.1 论文框架\n&emsp;&emsp;本论文具体框架如下所示，其中的Algorithm讲解请见下方1.2小节：  \n<center>![wmdpaper](2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances/WMDPaper.png)</center>  \n<center><b><font face=\"黑体\" size=2>图1 WMD论文框架</font></b></center>  \n\n### 1.2 算法详解  \n\n#### 1.2.1 Word2Vec Embedding介绍\n&emsp;&emsp;Mikolov提出word2vec模型，该模型为无监督模型，使用神经网络语言模型生成词向量。在word2vec的skip-gram模型中，根据上下文词训练得到概率最大的中心词词向量，具体的公式如下：  \n$$\\frac 1T\\sum_{t=1}^T\\sum_{j\\in nb(t)}{\\log p(w_j|w_t)}\\tag{1}$$\n其中nb(t)代表word$w_j$的上下文词。由于skip-gram模型简单的架构以及其中hierarchical softmax的应用，使得该模型可以在单机上每小时训练上亿单词。  \n\n#### 1.2.2 WMD算法讲解\n&emsp;&emsp;下面我们将详细讲解WMD算法的实现逻辑。  \n\n* __nBow Representation__  \n该算法首先将文档用nBOW向量$d\\in R^n$表示，其中的每个元素代表对应的单词$i_{th}$在该文档中出现的次数（经过归一化处理），具体如下：  \n<center>![nBow](2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances/nBow.jpg)</center>  \n<center><b><font face=\"黑体\" size=2>图2 文档的nBOW表示</font></b></center>  \n  \n* __Word Travel Cost__  \n本论文的目标是在文本距离的计算过程中加入单词对之间的语义相似度，衡量单词语义相似度的其中一种方法是使用它们各自在w2v embedding向量空间中的欧式距离来表示，即为：  \n$$c(i, j) = \\rVert x_i - x_j \\rVert_2\\tag{2}$$\n$c(i, j)$即表示两个word之间的“travel cost”。  \n  \n* __Document Distance__  \n基于上述nBow representation和word之间的travel cost，对于两篇文档doc1、doc2，设其nBow representation分别为$d$和$d'$，doc1中的单词$i$ Travel到doc2中的单词$j$的个数为$T_{ij}$，两个单词的$travel cost=c(i, j)$，于是有：<center>![doc representation](2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances/docRep.jpg)</center>  \n<center><b><font face=\"黑体\" size=2>图3 两文档映射的矩阵表示</font></b></center>  \n综上，可以得知doc1和doc2之间的文本距离可表示为：  \n$$\\sum_{i,j}T_{i,j}c(i, j)\\tag{3}$$\n  \n* __Transportation Problem__  \n根据Document Distance中得到的文本距离公式，可以知道WMD算法需要解决的问题可表示为：  \n$$min_{T\\geq 0}\\sum_{i,j=1}^n{T_{ij}c(i, j)}\\tag{4}$$\n$$\\begin{aligned}subject\\ to: \\sum_{j=1}^n{T_{ij} = d_i} \\quad \\forall i\\in \\{1,...,n\\} \\\\\\qquad \\qquad \\quad \\sum_{i=1}^n{T_{ij} = d'_j} \\quad \\forall j\\in \\{1,...,n\\}\\end{aligned}$$\n上述优化问题可以看作是the Earth Mover's Distance（EMD）问题的一个实例，EMD问题是一个研究很透彻的运输问题，已经有很成熟的解法。 \n  \n* __Visualization__  \n最后以下图中几个句子为例，对WMD算法进行可视化总结：  \n<center>![example](2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances/visualization.png)</center>  \n<center><b><font face=\"黑体\" size=2>图4 WMD算法举例</font></b></center>  \n\nTop图中句子$D_1$和$D_2$分别和$D_0$计算文本距离，首先对各句子去除停用词，发现$D_1$和$D_2$ 与 $D_0$之间的BOW/TF-IDF距离都是相同的。但是在图中WMD算法中，我们观察到，各句子之间的word travel都在希望的语义相似的单词之间进行，进而得到最终的文本距离。  \n\n#### 1.2.3 WMD计算优化\n&emsp;&emsp;WMD的最好平均时间复杂度为$O(p^3\\log p)$（p表示一篇文档中出现的不重复单词个数），对于文章中含有大量不重复单词或者文章数量众多的情况，wmd算法的代价太高。以下我们介绍几种利用求取WMD的lower bounds进行优化的算法：WCD & RWMD。  \n\n* __Word Centroid Distance__  \n\n>【向量范数定义】  \n>如果向量 x∈Rn 的某个实值函数f(x)=||x||满足：  \n>1. 正定性： ||x||≥0，且||x||=0当且仅当x=0；  \n>2. 齐次性：对任意实数 α ，都有||αx||=|α| ||x||;  \n>3. 三角不等式：对任意x,y∈Rn，都有||x+y||≤||x||+||y||;  \n>则称||x|| 为 Rn上的一个向量范数  \n\n&emsp;&emsp;根据上述向量范数的定义，可以推得“centroid”距离$\\rVert Xd-Xd'\\rVert$必定是WMD算法中两文本距离的lower bound：  \n$$\\begin{split}\\sum_{i,j=1}^n{T_{ij}c(i,j)} &= \\sum_{i,j=1}^n{T_{ij} \\rVert x_i - x'_j \\rVert _2} \\\\&= \\sum_{i,j=1}^n{\\rVert T_{ij}(x_i-x'_j) \\rVert_2} \\quad(范数的齐次性) \\\\&\\geq \\rVert \\sum_{i,j=1}^n{T_{ij}(x_i-x'_j) \\rVert_2} \\quad(范数的三角不等式性质) \\\\&=\\rVert \\sum_{i=1}^n\\left(\\sum_{j=1}^n{T_{ij}}\\right)x_i - \\sum_{j=1}^n\\left(\\sum_{i=1}^n{T_{ij}}\\right)x'_j \\rVert_2 \\\\&=\\rVert \\sum_{i=1}^n{d_ix_i}-\\sum_{j=1}^n{d'_jx'_j}\\rVert_2 \\\\&=\\rVert Xd - Xd' \\rVert_2\\end{split}\\tag{5}$$\n上述WCD算法的时间复杂度为$O(dp)$，可以在求解topK相似的文档时使用该算法加快确定较小的候选集。  \n  \n* __Relaxed Word Moving Distance__  \n&emsp;&emsp;尽管WDC算法计算很快，但是它的结果与WMD算法差距不够小。在下面介绍的RWMD算法中，我们将去掉其中一个约束条件进而得到WMD算法的lower bound，该算法可以得到与WMD更相近的结果，于是RWMD的优化目标如下：  \n$$min_{T\\geq 0}\\sum_{i,j=1}^n{T_{ij}c(i, j)}\\tag{6}$$\n$$subject\\ to: \\sum_{j=1}^n{T_{ij}=d_i\\quad \\forall i\\in \\{1,...,n\\}}$$  \n在RWMD算法中，可以将doc1中的每一个单词$i$都Travel到doc2中离它最近的单词$j$上来求得其最小值：  \n令$$T^*_{ij}=\\begin{cases} d_i\\quad if\\ j=argmin_jc(i,j) \\\\ 0 \\quad otherwise \\end{cases}$$，有  \n$$\\begin{split}\\sum_j{T_{ij}c(i,j) \\geq \\sum_j{T_{ij}c(i, j^*)}} =c(i, j^*)\\sum_j{T_{ij}} \\\\=c(i, j^*)d_i = \\sum_j{T^*{ij}c(i,j)}\\end{split}\\tag{7}$$  \n分别去掉WMD的两个约束条件，得到两个近似结果$l_1(d, d')$和$l_2(d, d')$，于是RWMD算法的最终结果为：  \n$$l_r(d, d') = max(l_1(d, d'), l_2(d, d'))\\tag{8}$$\n上述RWMD算法的时间复杂度为$O(p^2)$。  \n\n* __Prefetch and Prune__  \n&emsp;&emsp;本小结将介绍WCD+WMD+RWMD算法在问题“众多文档中寻找doc0的topK个最相似的文档”上的应用，具体解决步骤如下：  \n1）首先计算出所有文档到doc0的WCD距离，并且对于前k个文档计算具体的WMD距离；  \n2）对于剩余文档，计算其RWMD距离，并查看该距离是否要大于前k个文档的WMD距离：  \n&emsp;&emsp;如果大于，则可以prune该文档；  \n&emsp;&emsp;否则，计算该文档具体的WMD距离，看是否需要替换前k个文档。  \n\n## 2. 代码详述\n### 2.1 开源代码\n&emsp;&emsp;目前WMD算法的开源代码有：  \n\n* WMD论文作者源码：[Word Mover's Distance (WMD) from Matthew J Kusner](https://github.com/mkusner/wmd) ,使用单纯形法计算EMD，但单纯形法的时间复杂度不稳定，最大为指数级，大多数情况是超立方级；  \n\n* Gensim库中有WMD算法的实现，其调用了[pyemd](https://github.com/wmayner/pyemd)的c扩展，使用了Fast EMD算法，由于是python封装的wmd，计算非常慢，其调用方式为：from gensim.similarities import WmdSimilarity；\n  \n* github上的[Fast WMD](https://github.com/src-d/wmd-relax)，同样是python封装c，另外在此项目中给出了RWMD算法的实现。  \n  \n### 2.2 代码实现  \n&emsp;&emsp;以下介绍下我对wmd算法的实现思路、使用工具以及代码复现。  \n  \n#### 2.2.1 实现思路  \n1）对文档进行分词（英文使用空格分开，中文使用分词器）；  \n2）对每个分词进行词嵌入表示（本文中使用训练好的glove词向量）；  \n3）将wmd算法转化为矩阵形式，其为lp最优化问题，可使用现成的lp最优化工具（本文中使用cvxopt包）解决。  \n  \n#### 2.2.2 cvxopt.solver.lp接口  \n&emsp;&emsp;cvxopt.lp接口解决线性规划问题时，需先将问题转化为如下标准形式：  \n$$minimize\\quad c^Tx\\tag{9}$$\n$$\\begin{aligned}subject\\ to:Gx\\leq h \\\\Ax=b \\end{aligned}$$  \n将wmd算法转换为此形式，具体如下图所示：\n<center>![cvxopt Representation](2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances/cvxoptRep.jpg)</center>  \n<center><b><font face=\"黑体\" size=2>图5 cvxopt矩阵表示</font></b></center>  \n  \n#### 2.2.3 代码复现\n```python\nfrom cvxopt import matrix, solvers\nimport numpy as np\nimport math\n\n# 加载glove词向量\ndef load_embeddings(glovefile):\n    word_emds = {}\n    for line in glovefile:\n        eles = line.split(\" \")\n        word = eles[0]\n        vector = list(map(float, eles[1:]))\n        word_emds[word] = vector\n    return word_emds\n\n# 计算两个词向量之间的距离\ndef get_distance(emd1, emd2):\n    result = 0\n    for idx in range(0, len(emd1)):\n        val = pow(emd1[idx] - emd2[idx],2)\n        result += val\n    result = math.sqrt(result)\n    return result\n\n# 词频统计（nBow）\ndef get_nBow(word_list):\n    word_map = {}\n    length = len(word_list)\n    for word in word_list:\n        if word in word_map.keys():\n            word_map[word] += 1\n        else:\n            word_map[word] = 1\n    b = [val/length for val in word_map.values()]\n    return word_map, b\n\ndef WMD (sent1, sent2):\n    # 0. 分词、词向量、词频统计等预处理\n    word_list1 = sent1.split();\n    word_list2 = sent2.split();\n    \n    word_map1, b1 = get_nBow(word_list1)\n    word_map2, b2 = get_nBow(word_list2)    \n    \n    # 1. 生成目标函数矩阵\n    c_ij = []\n    for i in word_map1.keys():\n        for j in word_map2.keys():\n            word_emds1 = []\n            word_emds2 = []\n            if i in word_emds:\n                word_emds1 = word_emds[i]\n            else:\n                word_emds1 = [0 for x in range(100)]\n            if j in word_emds:\n                word_emds2 = word_emds[j]\n            else:\n                word_emds2 = [0 for x in range(100)]\n            distance = get_distance(word_emds1, word_emds2)\n            c_ij.append(distance)\n    \n    # 2. 等式约束条件\n    a = []\n    length1 = len(word_map1)\n    length2 = len(word_map2)\n    for i in range(length1):\n        line = []\n        start = [0.0 for x in range(i*length2)]\n        middle = [1.0 for x in range(length2)]\n        end = [0.0 for x in range((length1-i-1)*length2)]\n        line.extend(start)\n        line.extend(middle)\n        line.extend(end)\n        a.append(line)\n    for j in range(length2):\n        line = []\n        single = []\n        start = [0.0 for x in range(j)]\n        end = [0.0 for x in range(length2-j-1)]\n        single.extend(start)\n        single.append(1.0)\n        single.extend(end)\n        for i in range(length1):\n            line.extend(single)\n        a.append(line)        \n        \n    b = []\n    b.extend(b1)\n    b.extend(b2)\n    \n    # 3. 不等式约束条件\n    g = -np.eye(length1*length2)\n    h = np.zeros((length1*length2))\n    \n    # 4. 应用cvxopt.solver\n    c = matrix(c_ij)\n    A = matrix(np.array(a))\n    b = matrix(b)\n    G = matrix(g)\n    h = matrix(h) \n    \n    sol = solvers.lp(c,G,h,A,b,solver='glpk')\n    wmd_dist = sol['primal objective']\n    return wmd_dist\n```\n测试代码：  \n```python\nglovefile = open(\"/root/nlpTool/glove.6B/glove.6B.100d.txt\",\"r\",encoding=\"utf-8\")  \nword_emds = load_embeddings(glovefile)\nsent1 = \"people like this car\"\nsent2 = \"those guys enjoy driving that\"\nsent3 = \"Obama speaks to the media in Illinois.\"\nsent4 = \"The President greets the press in Chicago.\"\nsent5 = \"Beijing is China's capital.\"\nsent6 = \"The capital of England is London.\"\nprint(WMD(sent1, sent2))\nprint(WMD(sent1, sent1))\nprint(WMD(sent3, sent4))\nprint(WMD(sent5, sent6))\n```\n\n## 3. 相关论文及资料  \n[1] Kusner M, Sun Y, Kolkin N, et al. [From word embeddings to document distances[C]](http://proceedings.mlr.press/v37/kusnerb15.pdf)//International conference on machine learning. 2015: 957-966.  \n[2] Pele O, Werman M. [Fast and Robust Earth Mover’s Distances[J]](http://www.cs.ucf.edu/courses/cap6412/spr2014/papers/pele-ICCV2009.pdf).  \n[3]Rubner Y, Tomasi C, Guibas L J. [The Earth Mover's Distance as a Metric for Image Retrieval[J]](http://www.cs.cmu.edu/afs/.cs.cmu.edu/Web/People/efros/courses/AP06/Papers/rubner-jcviu-00.pdf).  \n[4] CVXOPT官方文档：[Solving a linear program](http://cvxopt.org/examples/tutorial/lp.html).  \n[5] CVXOPT官方文档：[Linearing Programming](http://cvxopt.org/userguide/coneprog.html#linear-programming).  \n[6] Blog about CVXOPT LP: [Linear Programming in Python with CVXOPT](https://scaron.info/blog/linear-programming-in-python-with-cvxopt.html).  \n[7] Gensim官方文档：[glove2word2vec的使用](https://radimrehurek.com/gensim/scripts/glove2word2vec.html).\n  \n以上为我对WMD论文的理解，文中若有错误之处，欢迎大家在评论区留言指正。","source":"_posts/2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances.md","raw":"---\ntitle: 'WMD论文详解及代码介绍:From_Word_Embeddings_to_Document_Distances'\ncategories: nlp\ntags:\n  - paper\nabbrlink: 8321bff9\ndate: 2020-10-03 13:37:10\nmathjax: true\n---\n&emsp;&emsp;本文对《From Word Embeddings to Document Distances》论文（以下简称“WMD论文”）进行了讲解，并对其代码实现进行了介绍。  \n\n## 1. 论文讲解\n&emsp;&emsp;在WMD论文中，作者提出了Word Mover's Distance算法用来计算文档之间的距离，该算法基于word embedding来表示句子中的词向量。同时作者将文本距离计算问题看作是the Earth Mover's Distance问题的一个实例，并提出了多种计算优化方法。以下是整个论文的框架，以及对WMD及其计算优化的详细讲解。\n<!--more-->  \n\n### 1.1 论文框架\n&emsp;&emsp;本论文具体框架如下所示，其中的Algorithm讲解请见下方1.2小节：  \n<center>![wmdpaper](2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances/WMDPaper.png)</center>  \n<center><b><font face=\"黑体\" size=2>图1 WMD论文框架</font></b></center>  \n\n### 1.2 算法详解  \n\n#### 1.2.1 Word2Vec Embedding介绍\n&emsp;&emsp;Mikolov提出word2vec模型，该模型为无监督模型，使用神经网络语言模型生成词向量。在word2vec的skip-gram模型中，根据上下文词训练得到概率最大的中心词词向量，具体的公式如下：  \n$$\\frac 1T\\sum_{t=1}^T\\sum_{j\\in nb(t)}{\\log p(w_j|w_t)}\\tag{1}$$\n其中nb(t)代表word$w_j$的上下文词。由于skip-gram模型简单的架构以及其中hierarchical softmax的应用，使得该模型可以在单机上每小时训练上亿单词。  \n\n#### 1.2.2 WMD算法讲解\n&emsp;&emsp;下面我们将详细讲解WMD算法的实现逻辑。  \n\n* __nBow Representation__  \n该算法首先将文档用nBOW向量$d\\in R^n$表示，其中的每个元素代表对应的单词$i_{th}$在该文档中出现的次数（经过归一化处理），具体如下：  \n<center>![nBow](2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances/nBow.jpg)</center>  \n<center><b><font face=\"黑体\" size=2>图2 文档的nBOW表示</font></b></center>  \n  \n* __Word Travel Cost__  \n本论文的目标是在文本距离的计算过程中加入单词对之间的语义相似度，衡量单词语义相似度的其中一种方法是使用它们各自在w2v embedding向量空间中的欧式距离来表示，即为：  \n$$c(i, j) = \\rVert x_i - x_j \\rVert_2\\tag{2}$$\n$c(i, j)$即表示两个word之间的“travel cost”。  \n  \n* __Document Distance__  \n基于上述nBow representation和word之间的travel cost，对于两篇文档doc1、doc2，设其nBow representation分别为$d$和$d'$，doc1中的单词$i$ Travel到doc2中的单词$j$的个数为$T_{ij}$，两个单词的$travel cost=c(i, j)$，于是有：<center>![doc representation](2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances/docRep.jpg)</center>  \n<center><b><font face=\"黑体\" size=2>图3 两文档映射的矩阵表示</font></b></center>  \n综上，可以得知doc1和doc2之间的文本距离可表示为：  \n$$\\sum_{i,j}T_{i,j}c(i, j)\\tag{3}$$\n  \n* __Transportation Problem__  \n根据Document Distance中得到的文本距离公式，可以知道WMD算法需要解决的问题可表示为：  \n$$min_{T\\geq 0}\\sum_{i,j=1}^n{T_{ij}c(i, j)}\\tag{4}$$\n$$\\begin{aligned}subject\\ to: \\sum_{j=1}^n{T_{ij} = d_i} \\quad \\forall i\\in \\{1,...,n\\} \\\\\\qquad \\qquad \\quad \\sum_{i=1}^n{T_{ij} = d'_j} \\quad \\forall j\\in \\{1,...,n\\}\\end{aligned}$$\n上述优化问题可以看作是the Earth Mover's Distance（EMD）问题的一个实例，EMD问题是一个研究很透彻的运输问题，已经有很成熟的解法。 \n  \n* __Visualization__  \n最后以下图中几个句子为例，对WMD算法进行可视化总结：  \n<center>![example](2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances/visualization.png)</center>  \n<center><b><font face=\"黑体\" size=2>图4 WMD算法举例</font></b></center>  \n\nTop图中句子$D_1$和$D_2$分别和$D_0$计算文本距离，首先对各句子去除停用词，发现$D_1$和$D_2$ 与 $D_0$之间的BOW/TF-IDF距离都是相同的。但是在图中WMD算法中，我们观察到，各句子之间的word travel都在希望的语义相似的单词之间进行，进而得到最终的文本距离。  \n\n#### 1.2.3 WMD计算优化\n&emsp;&emsp;WMD的最好平均时间复杂度为$O(p^3\\log p)$（p表示一篇文档中出现的不重复单词个数），对于文章中含有大量不重复单词或者文章数量众多的情况，wmd算法的代价太高。以下我们介绍几种利用求取WMD的lower bounds进行优化的算法：WCD & RWMD。  \n\n* __Word Centroid Distance__  \n\n>【向量范数定义】  \n>如果向量 x∈Rn 的某个实值函数f(x)=||x||满足：  \n>1. 正定性： ||x||≥0，且||x||=0当且仅当x=0；  \n>2. 齐次性：对任意实数 α ，都有||αx||=|α| ||x||;  \n>3. 三角不等式：对任意x,y∈Rn，都有||x+y||≤||x||+||y||;  \n>则称||x|| 为 Rn上的一个向量范数  \n\n&emsp;&emsp;根据上述向量范数的定义，可以推得“centroid”距离$\\rVert Xd-Xd'\\rVert$必定是WMD算法中两文本距离的lower bound：  \n$$\\begin{split}\\sum_{i,j=1}^n{T_{ij}c(i,j)} &= \\sum_{i,j=1}^n{T_{ij} \\rVert x_i - x'_j \\rVert _2} \\\\&= \\sum_{i,j=1}^n{\\rVert T_{ij}(x_i-x'_j) \\rVert_2} \\quad(范数的齐次性) \\\\&\\geq \\rVert \\sum_{i,j=1}^n{T_{ij}(x_i-x'_j) \\rVert_2} \\quad(范数的三角不等式性质) \\\\&=\\rVert \\sum_{i=1}^n\\left(\\sum_{j=1}^n{T_{ij}}\\right)x_i - \\sum_{j=1}^n\\left(\\sum_{i=1}^n{T_{ij}}\\right)x'_j \\rVert_2 \\\\&=\\rVert \\sum_{i=1}^n{d_ix_i}-\\sum_{j=1}^n{d'_jx'_j}\\rVert_2 \\\\&=\\rVert Xd - Xd' \\rVert_2\\end{split}\\tag{5}$$\n上述WCD算法的时间复杂度为$O(dp)$，可以在求解topK相似的文档时使用该算法加快确定较小的候选集。  \n  \n* __Relaxed Word Moving Distance__  \n&emsp;&emsp;尽管WDC算法计算很快，但是它的结果与WMD算法差距不够小。在下面介绍的RWMD算法中，我们将去掉其中一个约束条件进而得到WMD算法的lower bound，该算法可以得到与WMD更相近的结果，于是RWMD的优化目标如下：  \n$$min_{T\\geq 0}\\sum_{i,j=1}^n{T_{ij}c(i, j)}\\tag{6}$$\n$$subject\\ to: \\sum_{j=1}^n{T_{ij}=d_i\\quad \\forall i\\in \\{1,...,n\\}}$$  \n在RWMD算法中，可以将doc1中的每一个单词$i$都Travel到doc2中离它最近的单词$j$上来求得其最小值：  \n令$$T^*_{ij}=\\begin{cases} d_i\\quad if\\ j=argmin_jc(i,j) \\\\ 0 \\quad otherwise \\end{cases}$$，有  \n$$\\begin{split}\\sum_j{T_{ij}c(i,j) \\geq \\sum_j{T_{ij}c(i, j^*)}} =c(i, j^*)\\sum_j{T_{ij}} \\\\=c(i, j^*)d_i = \\sum_j{T^*{ij}c(i,j)}\\end{split}\\tag{7}$$  \n分别去掉WMD的两个约束条件，得到两个近似结果$l_1(d, d')$和$l_2(d, d')$，于是RWMD算法的最终结果为：  \n$$l_r(d, d') = max(l_1(d, d'), l_2(d, d'))\\tag{8}$$\n上述RWMD算法的时间复杂度为$O(p^2)$。  \n\n* __Prefetch and Prune__  \n&emsp;&emsp;本小结将介绍WCD+WMD+RWMD算法在问题“众多文档中寻找doc0的topK个最相似的文档”上的应用，具体解决步骤如下：  \n1）首先计算出所有文档到doc0的WCD距离，并且对于前k个文档计算具体的WMD距离；  \n2）对于剩余文档，计算其RWMD距离，并查看该距离是否要大于前k个文档的WMD距离：  \n&emsp;&emsp;如果大于，则可以prune该文档；  \n&emsp;&emsp;否则，计算该文档具体的WMD距离，看是否需要替换前k个文档。  \n\n## 2. 代码详述\n### 2.1 开源代码\n&emsp;&emsp;目前WMD算法的开源代码有：  \n\n* WMD论文作者源码：[Word Mover's Distance (WMD) from Matthew J Kusner](https://github.com/mkusner/wmd) ,使用单纯形法计算EMD，但单纯形法的时间复杂度不稳定，最大为指数级，大多数情况是超立方级；  \n\n* Gensim库中有WMD算法的实现，其调用了[pyemd](https://github.com/wmayner/pyemd)的c扩展，使用了Fast EMD算法，由于是python封装的wmd，计算非常慢，其调用方式为：from gensim.similarities import WmdSimilarity；\n  \n* github上的[Fast WMD](https://github.com/src-d/wmd-relax)，同样是python封装c，另外在此项目中给出了RWMD算法的实现。  \n  \n### 2.2 代码实现  \n&emsp;&emsp;以下介绍下我对wmd算法的实现思路、使用工具以及代码复现。  \n  \n#### 2.2.1 实现思路  \n1）对文档进行分词（英文使用空格分开，中文使用分词器）；  \n2）对每个分词进行词嵌入表示（本文中使用训练好的glove词向量）；  \n3）将wmd算法转化为矩阵形式，其为lp最优化问题，可使用现成的lp最优化工具（本文中使用cvxopt包）解决。  \n  \n#### 2.2.2 cvxopt.solver.lp接口  \n&emsp;&emsp;cvxopt.lp接口解决线性规划问题时，需先将问题转化为如下标准形式：  \n$$minimize\\quad c^Tx\\tag{9}$$\n$$\\begin{aligned}subject\\ to:Gx\\leq h \\\\Ax=b \\end{aligned}$$  \n将wmd算法转换为此形式，具体如下图所示：\n<center>![cvxopt Representation](2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances/cvxoptRep.jpg)</center>  \n<center><b><font face=\"黑体\" size=2>图5 cvxopt矩阵表示</font></b></center>  \n  \n#### 2.2.3 代码复现\n```python\nfrom cvxopt import matrix, solvers\nimport numpy as np\nimport math\n\n# 加载glove词向量\ndef load_embeddings(glovefile):\n    word_emds = {}\n    for line in glovefile:\n        eles = line.split(\" \")\n        word = eles[0]\n        vector = list(map(float, eles[1:]))\n        word_emds[word] = vector\n    return word_emds\n\n# 计算两个词向量之间的距离\ndef get_distance(emd1, emd2):\n    result = 0\n    for idx in range(0, len(emd1)):\n        val = pow(emd1[idx] - emd2[idx],2)\n        result += val\n    result = math.sqrt(result)\n    return result\n\n# 词频统计（nBow）\ndef get_nBow(word_list):\n    word_map = {}\n    length = len(word_list)\n    for word in word_list:\n        if word in word_map.keys():\n            word_map[word] += 1\n        else:\n            word_map[word] = 1\n    b = [val/length for val in word_map.values()]\n    return word_map, b\n\ndef WMD (sent1, sent2):\n    # 0. 分词、词向量、词频统计等预处理\n    word_list1 = sent1.split();\n    word_list2 = sent2.split();\n    \n    word_map1, b1 = get_nBow(word_list1)\n    word_map2, b2 = get_nBow(word_list2)    \n    \n    # 1. 生成目标函数矩阵\n    c_ij = []\n    for i in word_map1.keys():\n        for j in word_map2.keys():\n            word_emds1 = []\n            word_emds2 = []\n            if i in word_emds:\n                word_emds1 = word_emds[i]\n            else:\n                word_emds1 = [0 for x in range(100)]\n            if j in word_emds:\n                word_emds2 = word_emds[j]\n            else:\n                word_emds2 = [0 for x in range(100)]\n            distance = get_distance(word_emds1, word_emds2)\n            c_ij.append(distance)\n    \n    # 2. 等式约束条件\n    a = []\n    length1 = len(word_map1)\n    length2 = len(word_map2)\n    for i in range(length1):\n        line = []\n        start = [0.0 for x in range(i*length2)]\n        middle = [1.0 for x in range(length2)]\n        end = [0.0 for x in range((length1-i-1)*length2)]\n        line.extend(start)\n        line.extend(middle)\n        line.extend(end)\n        a.append(line)\n    for j in range(length2):\n        line = []\n        single = []\n        start = [0.0 for x in range(j)]\n        end = [0.0 for x in range(length2-j-1)]\n        single.extend(start)\n        single.append(1.0)\n        single.extend(end)\n        for i in range(length1):\n            line.extend(single)\n        a.append(line)        \n        \n    b = []\n    b.extend(b1)\n    b.extend(b2)\n    \n    # 3. 不等式约束条件\n    g = -np.eye(length1*length2)\n    h = np.zeros((length1*length2))\n    \n    # 4. 应用cvxopt.solver\n    c = matrix(c_ij)\n    A = matrix(np.array(a))\n    b = matrix(b)\n    G = matrix(g)\n    h = matrix(h) \n    \n    sol = solvers.lp(c,G,h,A,b,solver='glpk')\n    wmd_dist = sol['primal objective']\n    return wmd_dist\n```\n测试代码：  \n```python\nglovefile = open(\"/root/nlpTool/glove.6B/glove.6B.100d.txt\",\"r\",encoding=\"utf-8\")  \nword_emds = load_embeddings(glovefile)\nsent1 = \"people like this car\"\nsent2 = \"those guys enjoy driving that\"\nsent3 = \"Obama speaks to the media in Illinois.\"\nsent4 = \"The President greets the press in Chicago.\"\nsent5 = \"Beijing is China's capital.\"\nsent6 = \"The capital of England is London.\"\nprint(WMD(sent1, sent2))\nprint(WMD(sent1, sent1))\nprint(WMD(sent3, sent4))\nprint(WMD(sent5, sent6))\n```\n\n## 3. 相关论文及资料  \n[1] Kusner M, Sun Y, Kolkin N, et al. [From word embeddings to document distances[C]](http://proceedings.mlr.press/v37/kusnerb15.pdf)//International conference on machine learning. 2015: 957-966.  \n[2] Pele O, Werman M. [Fast and Robust Earth Mover’s Distances[J]](http://www.cs.ucf.edu/courses/cap6412/spr2014/papers/pele-ICCV2009.pdf).  \n[3]Rubner Y, Tomasi C, Guibas L J. [The Earth Mover's Distance as a Metric for Image Retrieval[J]](http://www.cs.cmu.edu/afs/.cs.cmu.edu/Web/People/efros/courses/AP06/Papers/rubner-jcviu-00.pdf).  \n[4] CVXOPT官方文档：[Solving a linear program](http://cvxopt.org/examples/tutorial/lp.html).  \n[5] CVXOPT官方文档：[Linearing Programming](http://cvxopt.org/userguide/coneprog.html#linear-programming).  \n[6] Blog about CVXOPT LP: [Linear Programming in Python with CVXOPT](https://scaron.info/blog/linear-programming-in-python-with-cvxopt.html).  \n[7] Gensim官方文档：[glove2word2vec的使用](https://radimrehurek.com/gensim/scripts/glove2word2vec.html).\n  \n以上为我对WMD论文的理解，文中若有错误之处，欢迎大家在评论区留言指正。","slug":"WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances","published":1,"updated":"2021-11-02T15:17:01.912Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckvi8p0a80003ggsjhw9t8uzo","content":"<p>&emsp;&emsp;本文对《From Word Embeddings to Document Distances》论文（以下简称“WMD论文”）进行了讲解，并对其代码实现进行了介绍。  </p>\n<h2 id=\"1-论文讲解\"><a href=\"#1-论文讲解\" class=\"headerlink\" title=\"1. 论文讲解\"></a>1. 论文讲解</h2><p>&emsp;&emsp;在WMD论文中，作者提出了Word Mover’s Distance算法用来计算文档之间的距离，该算法基于word embedding来表示句子中的词向量。同时作者将文本距离计算问题看作是the Earth Mover’s Distance问题的一个实例，并提出了多种计算优化方法。以下是整个论文的框架，以及对WMD及其计算优化的详细讲解。<br><a id=\"more\"></a>  </p>\n<h3 id=\"1-1-论文框架\"><a href=\"#1-1-论文框架\" class=\"headerlink\" title=\"1.1 论文框架\"></a>1.1 论文框架</h3><p>&emsp;&emsp;本论文具体框架如下所示，其中的Algorithm讲解请见下方1.2小节：  </p>\n<center>![wmdpaper](2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances/WMDPaper.png)</center>  \n<center><b><font face=\"黑体\" size=\"2\">图1 WMD论文框架</font></b></center>  \n\n<h3 id=\"1-2-算法详解\"><a href=\"#1-2-算法详解\" class=\"headerlink\" title=\"1.2 算法详解\"></a>1.2 算法详解</h3><h4 id=\"1-2-1-Word2Vec-Embedding介绍\"><a href=\"#1-2-1-Word2Vec-Embedding介绍\" class=\"headerlink\" title=\"1.2.1 Word2Vec Embedding介绍\"></a>1.2.1 Word2Vec Embedding介绍</h4><p>&emsp;&emsp;Mikolov提出word2vec模型，该模型为无监督模型，使用神经网络语言模型生成词向量。在word2vec的skip-gram模型中，根据上下文词训练得到概率最大的中心词词向量，具体的公式如下：  </p>\n<script type=\"math/tex; mode=display\">\\frac 1T\\sum_{t=1}^T\\sum_{j\\in nb(t)}{\\log p(w_j|w_t)}\\tag{1}</script><p>其中nb(t)代表word$w_j$的上下文词。由于skip-gram模型简单的架构以及其中hierarchical softmax的应用，使得该模型可以在单机上每小时训练上亿单词。  </p>\n<h4 id=\"1-2-2-WMD算法讲解\"><a href=\"#1-2-2-WMD算法讲解\" class=\"headerlink\" title=\"1.2.2 WMD算法讲解\"></a>1.2.2 WMD算法讲解</h4><p>&emsp;&emsp;下面我们将详细讲解WMD算法的实现逻辑。  </p>\n<ul>\n<li><p><strong>nBow Representation</strong><br>该算法首先将文档用nBOW向量$d\\in R^n$表示，其中的每个元素代表对应的单词$i_{th}$在该文档中出现的次数（经过归一化处理），具体如下：  </p>\n<center>![nBow](2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances/nBow.jpg)</center>  \n<center><b><font face=\"黑体\" size=\"2\">图2 文档的nBOW表示</font></b></center>  \n</li>\n<li><p><strong>Word Travel Cost</strong><br>本论文的目标是在文本距离的计算过程中加入单词对之间的语义相似度，衡量单词语义相似度的其中一种方法是使用它们各自在w2v embedding向量空间中的欧式距离来表示，即为：  </p>\n<script type=\"math/tex; mode=display\">c(i, j) = \\rVert x_i - x_j \\rVert_2\\tag{2}</script><p>$c(i, j)$即表示两个word之间的“travel cost”。  </p>\n</li>\n<li><p><strong>Document Distance</strong><br>基于上述nBow representation和word之间的travel cost，对于两篇文档doc1、doc2，设其nBow representation分别为$d$和$d’$，doc1中的单词$i$ Travel到doc2中的单词$j$的个数为$T_{ij}$，两个单词的$travel cost=c(i, j)$，于是有：<center>![doc representation](2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances/docRep.jpg)</center><br><center><b><font face=\"黑体\" size=\"2\">图3 两文档映射的矩阵表示</font></b></center><br>综上，可以得知doc1和doc2之间的文本距离可表示为：  </p>\n<script type=\"math/tex; mode=display\">\\sum_{i,j}T_{i,j}c(i, j)\\tag{3}</script></li>\n<li><p><strong>Transportation Problem</strong><br>根据Document Distance中得到的文本距离公式，可以知道WMD算法需要解决的问题可表示为：  </p>\n<script type=\"math/tex; mode=display\">min_{T\\geq 0}\\sum_{i,j=1}^n{T_{ij}c(i, j)}\\tag{4}</script><script type=\"math/tex; mode=display\">\\begin{aligned}subject\\ to: \\sum_{j=1}^n{T_{ij} = d_i} \\quad \\forall i\\in \\{1,...,n\\} \\\\\\qquad \\qquad \\quad \\sum_{i=1}^n{T_{ij} = d'_j} \\quad \\forall j\\in \\{1,...,n\\}\\end{aligned}</script><p>上述优化问题可以看作是the Earth Mover’s Distance（EMD）问题的一个实例，EMD问题是一个研究很透彻的运输问题，已经有很成熟的解法。 </p>\n</li>\n<li><p><strong>Visualization</strong><br>最后以下图中几个句子为例，对WMD算法进行可视化总结：  </p>\n<center>![example](2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances/visualization.png)</center>  \n<center><b><font face=\"黑体\" size=\"2\">图4 WMD算法举例</font></b></center>  \n\n</li>\n</ul>\n<p>Top图中句子$D_1$和$D_2$分别和$D_0$计算文本距离，首先对各句子去除停用词，发现$D_1$和$D_2$ 与 $D_0$之间的BOW/TF-IDF距离都是相同的。但是在图中WMD算法中，我们观察到，各句子之间的word travel都在希望的语义相似的单词之间进行，进而得到最终的文本距离。  </p>\n<h4 id=\"1-2-3-WMD计算优化\"><a href=\"#1-2-3-WMD计算优化\" class=\"headerlink\" title=\"1.2.3 WMD计算优化\"></a>1.2.3 WMD计算优化</h4><p>&emsp;&emsp;WMD的最好平均时间复杂度为$O(p^3\\log p)$（p表示一篇文档中出现的不重复单词个数），对于文章中含有大量不重复单词或者文章数量众多的情况，wmd算法的代价太高。以下我们介绍几种利用求取WMD的lower bounds进行优化的算法：WCD &amp; RWMD。  </p>\n<ul>\n<li><strong>Word Centroid Distance</strong>  </li>\n</ul>\n<blockquote>\n<p>【向量范数定义】<br>如果向量 x∈Rn 的某个实值函数f(x)=||x||满足：  </p>\n<ol>\n<li>正定性： ||x||≥0，且||x||=0当且仅当x=0；  </li>\n<li>齐次性：对任意实数 α ，都有||αx||=|α| ||x||;  </li>\n<li>三角不等式：对任意x,y∈Rn，都有||x+y||≤||x||+||y||;<br>则称||x|| 为 Rn上的一个向量范数  </li>\n</ol>\n</blockquote>\n<p>&emsp;&emsp;根据上述向量范数的定义，可以推得“centroid”距离$\\rVert Xd-Xd’\\rVert$必定是WMD算法中两文本距离的lower bound：  </p>\n<script type=\"math/tex; mode=display\">\\begin{split}\\sum_{i,j=1}^n{T_{ij}c(i,j)} &= \\sum_{i,j=1}^n{T_{ij} \\rVert x_i - x'_j \\rVert _2} \\\\&= \\sum_{i,j=1}^n{\\rVert T_{ij}(x_i-x'_j) \\rVert_2} \\quad(范数的齐次性) \\\\&\\geq \\rVert \\sum_{i,j=1}^n{T_{ij}(x_i-x'_j) \\rVert_2} \\quad(范数的三角不等式性质) \\\\&=\\rVert \\sum_{i=1}^n\\left(\\sum_{j=1}^n{T_{ij}}\\right)x_i - \\sum_{j=1}^n\\left(\\sum_{i=1}^n{T_{ij}}\\right)x'_j \\rVert_2 \\\\&=\\rVert \\sum_{i=1}^n{d_ix_i}-\\sum_{j=1}^n{d'_jx'_j}\\rVert_2 \\\\&=\\rVert Xd - Xd' \\rVert_2\\end{split}\\tag{5}</script><p>上述WCD算法的时间复杂度为$O(dp)$，可以在求解topK相似的文档时使用该算法加快确定较小的候选集。  </p>\n<ul>\n<li><p><strong>Relaxed Word Moving Distance</strong><br>&emsp;&emsp;尽管WDC算法计算很快，但是它的结果与WMD算法差距不够小。在下面介绍的RWMD算法中，我们将去掉其中一个约束条件进而得到WMD算法的lower bound，该算法可以得到与WMD更相近的结果，于是RWMD的优化目标如下：  </p>\n<script type=\"math/tex; mode=display\">min_{T\\geq 0}\\sum_{i,j=1}^n{T_{ij}c(i, j)}\\tag{6}</script><script type=\"math/tex; mode=display\">subject\\ to: \\sum_{j=1}^n{T_{ij}=d_i\\quad \\forall i\\in \\{1,...,n\\}}</script><p>在RWMD算法中，可以将doc1中的每一个单词$i$都Travel到doc2中离它最近的单词$j$上来求得其最小值：<br>令<script type=\"math/tex\">T^*_{ij}=\\begin{cases} d_i\\quad if\\ j=argmin_jc(i,j) \\\\ 0 \\quad otherwise \\end{cases}</script>，有  </p>\n<script type=\"math/tex; mode=display\">\\begin{split}\\sum_j{T_{ij}c(i,j) \\geq \\sum_j{T_{ij}c(i, j^*)}} =c(i, j^*)\\sum_j{T_{ij}} \\\\=c(i, j^*)d_i = \\sum_j{T^*{ij}c(i,j)}\\end{split}\\tag{7}</script><p>分别去掉WMD的两个约束条件，得到两个近似结果$l_1(d, d’)$和$l_2(d, d’)$，于是RWMD算法的最终结果为：  </p>\n<script type=\"math/tex; mode=display\">l_r(d, d') = max(l_1(d, d'), l_2(d, d'))\\tag{8}</script><p>上述RWMD算法的时间复杂度为$O(p^2)$。  </p>\n</li>\n<li><p><strong>Prefetch and Prune</strong><br>&emsp;&emsp;本小结将介绍WCD+WMD+RWMD算法在问题“众多文档中寻找doc0的topK个最相似的文档”上的应用，具体解决步骤如下：<br>1）首先计算出所有文档到doc0的WCD距离，并且对于前k个文档计算具体的WMD距离；<br>2）对于剩余文档，计算其RWMD距离，并查看该距离是否要大于前k个文档的WMD距离：<br>&emsp;&emsp;如果大于，则可以prune该文档；<br>&emsp;&emsp;否则，计算该文档具体的WMD距离，看是否需要替换前k个文档。  </p>\n</li>\n</ul>\n<h2 id=\"2-代码详述\"><a href=\"#2-代码详述\" class=\"headerlink\" title=\"2. 代码详述\"></a>2. 代码详述</h2><h3 id=\"2-1-开源代码\"><a href=\"#2-1-开源代码\" class=\"headerlink\" title=\"2.1 开源代码\"></a>2.1 开源代码</h3><p>&emsp;&emsp;目前WMD算法的开源代码有：  </p>\n<ul>\n<li><p>WMD论文作者源码：<a href=\"https://github.com/mkusner/wmd\">Word Mover’s Distance (WMD) from Matthew J Kusner</a> ,使用单纯形法计算EMD，但单纯形法的时间复杂度不稳定，最大为指数级，大多数情况是超立方级；  </p>\n</li>\n<li><p>Gensim库中有WMD算法的实现，其调用了<a href=\"https://github.com/wmayner/pyemd\">pyemd</a>的c扩展，使用了Fast EMD算法，由于是python封装的wmd，计算非常慢，其调用方式为：from gensim.similarities import WmdSimilarity；</p>\n</li>\n<li><p>github上的<a href=\"https://github.com/src-d/wmd-relax\">Fast WMD</a>，同样是python封装c，另外在此项目中给出了RWMD算法的实现。  </p>\n</li>\n</ul>\n<h3 id=\"2-2-代码实现\"><a href=\"#2-2-代码实现\" class=\"headerlink\" title=\"2.2 代码实现\"></a>2.2 代码实现</h3><p>&emsp;&emsp;以下介绍下我对wmd算法的实现思路、使用工具以及代码复现。  </p>\n<h4 id=\"2-2-1-实现思路\"><a href=\"#2-2-1-实现思路\" class=\"headerlink\" title=\"2.2.1 实现思路\"></a>2.2.1 实现思路</h4><p>1）对文档进行分词（英文使用空格分开，中文使用分词器）；<br>2）对每个分词进行词嵌入表示（本文中使用训练好的glove词向量）；<br>3）将wmd算法转化为矩阵形式，其为lp最优化问题，可使用现成的lp最优化工具（本文中使用cvxopt包）解决。  </p>\n<h4 id=\"2-2-2-cvxopt-solver-lp接口\"><a href=\"#2-2-2-cvxopt-solver-lp接口\" class=\"headerlink\" title=\"2.2.2 cvxopt.solver.lp接口\"></a>2.2.2 cvxopt.solver.lp接口</h4><p>&emsp;&emsp;cvxopt.lp接口解决线性规划问题时，需先将问题转化为如下标准形式：  </p>\n<script type=\"math/tex; mode=display\">minimize\\quad c^Tx\\tag{9}</script><script type=\"math/tex; mode=display\">\\begin{aligned}subject\\ to:Gx\\leq h \\\\Ax=b \\end{aligned}</script><p>将wmd算法转换为此形式，具体如下图所示：</p>\n<center>![cvxopt Representation](2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances/cvxoptRep.jpg)</center>  \n<center><b><font face=\"黑体\" size=\"2\">图5 cvxopt矩阵表示</font></b></center>  \n\n<h4 id=\"2-2-3-代码复现\"><a href=\"#2-2-3-代码复现\" class=\"headerlink\" title=\"2.2.3 代码复现\"></a>2.2.3 代码复现</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> cvxopt <span class=\"keyword\">import</span> matrix, solvers</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 加载glove词向量</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">load_embeddings</span>(<span class=\"params\">glovefile</span>):</span></span><br><span class=\"line\">    word_emds = &#123;&#125;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> glovefile:</span><br><span class=\"line\">        eles = line.split(<span class=\"string\">&quot; &quot;</span>)</span><br><span class=\"line\">        word = eles[<span class=\"number\">0</span>]</span><br><span class=\"line\">        vector = list(map(float, eles[<span class=\"number\">1</span>:]))</span><br><span class=\"line\">        word_emds[word] = vector</span><br><span class=\"line\">    <span class=\"keyword\">return</span> word_emds</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 计算两个词向量之间的距离</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">get_distance</span>(<span class=\"params\">emd1, emd2</span>):</span></span><br><span class=\"line\">    result = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> idx <span class=\"keyword\">in</span> range(<span class=\"number\">0</span>, len(emd1)):</span><br><span class=\"line\">        val = pow(emd1[idx] - emd2[idx],<span class=\"number\">2</span>)</span><br><span class=\"line\">        result += val</span><br><span class=\"line\">    result = math.sqrt(result)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> result</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 词频统计（nBow）</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">get_nBow</span>(<span class=\"params\">word_list</span>):</span></span><br><span class=\"line\">    word_map = &#123;&#125;</span><br><span class=\"line\">    length = len(word_list)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> word <span class=\"keyword\">in</span> word_list:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> word <span class=\"keyword\">in</span> word_map.keys():</span><br><span class=\"line\">            word_map[word] += <span class=\"number\">1</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            word_map[word] = <span class=\"number\">1</span></span><br><span class=\"line\">    b = [val/length <span class=\"keyword\">for</span> val <span class=\"keyword\">in</span> word_map.values()]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> word_map, b</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">WMD</span> (<span class=\"params\">sent1, sent2</span>):</span></span><br><span class=\"line\">    <span class=\"comment\"># 0. 分词、词向量、词频统计等预处理</span></span><br><span class=\"line\">    word_list1 = sent1.split();</span><br><span class=\"line\">    word_list2 = sent2.split();</span><br><span class=\"line\">    </span><br><span class=\"line\">    word_map1, b1 = get_nBow(word_list1)</span><br><span class=\"line\">    word_map2, b2 = get_nBow(word_list2)    </span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># 1. 生成目标函数矩阵</span></span><br><span class=\"line\">    c_ij = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> word_map1.keys():</span><br><span class=\"line\">        <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> word_map2.keys():</span><br><span class=\"line\">            word_emds1 = []</span><br><span class=\"line\">            word_emds2 = []</span><br><span class=\"line\">            <span class=\"keyword\">if</span> i <span class=\"keyword\">in</span> word_emds:</span><br><span class=\"line\">                word_emds1 = word_emds[i]</span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                word_emds1 = [<span class=\"number\">0</span> <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(<span class=\"number\">100</span>)]</span><br><span class=\"line\">            <span class=\"keyword\">if</span> j <span class=\"keyword\">in</span> word_emds:</span><br><span class=\"line\">                word_emds2 = word_emds[j]</span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                word_emds2 = [<span class=\"number\">0</span> <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(<span class=\"number\">100</span>)]</span><br><span class=\"line\">            distance = get_distance(word_emds1, word_emds2)</span><br><span class=\"line\">            c_ij.append(distance)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># 2. 等式约束条件</span></span><br><span class=\"line\">    a = []</span><br><span class=\"line\">    length1 = len(word_map1)</span><br><span class=\"line\">    length2 = len(word_map2)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(length1):</span><br><span class=\"line\">        line = []</span><br><span class=\"line\">        start = [<span class=\"number\">0.0</span> <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(i*length2)]</span><br><span class=\"line\">        middle = [<span class=\"number\">1.0</span> <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(length2)]</span><br><span class=\"line\">        end = [<span class=\"number\">0.0</span> <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range((length1-i<span class=\"number\">-1</span>)*length2)]</span><br><span class=\"line\">        line.extend(start)</span><br><span class=\"line\">        line.extend(middle)</span><br><span class=\"line\">        line.extend(end)</span><br><span class=\"line\">        a.append(line)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(length2):</span><br><span class=\"line\">        line = []</span><br><span class=\"line\">        single = []</span><br><span class=\"line\">        start = [<span class=\"number\">0.0</span> <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(j)]</span><br><span class=\"line\">        end = [<span class=\"number\">0.0</span> <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(length2-j<span class=\"number\">-1</span>)]</span><br><span class=\"line\">        single.extend(start)</span><br><span class=\"line\">        single.append(<span class=\"number\">1.0</span>)</span><br><span class=\"line\">        single.extend(end)</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(length1):</span><br><span class=\"line\">            line.extend(single)</span><br><span class=\"line\">        a.append(line)        </span><br><span class=\"line\">        </span><br><span class=\"line\">    b = []</span><br><span class=\"line\">    b.extend(b1)</span><br><span class=\"line\">    b.extend(b2)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># 3. 不等式约束条件</span></span><br><span class=\"line\">    g = -np.eye(length1*length2)</span><br><span class=\"line\">    h = np.zeros((length1*length2))</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># 4. 应用cvxopt.solver</span></span><br><span class=\"line\">    c = matrix(c_ij)</span><br><span class=\"line\">    A = matrix(np.array(a))</span><br><span class=\"line\">    b = matrix(b)</span><br><span class=\"line\">    G = matrix(g)</span><br><span class=\"line\">    h = matrix(h) </span><br><span class=\"line\">    </span><br><span class=\"line\">    sol = solvers.lp(c,G,h,A,b,solver=<span class=\"string\">&#x27;glpk&#x27;</span>)</span><br><span class=\"line\">    wmd_dist = sol[<span class=\"string\">&#x27;primal objective&#x27;</span>]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> wmd_dist</span><br></pre></td></tr></table></figure>\n<p>测试代码：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">glovefile = open(<span class=\"string\">&quot;/root/nlpTool/glove.6B/glove.6B.100d.txt&quot;</span>,<span class=\"string\">&quot;r&quot;</span>,encoding=<span class=\"string\">&quot;utf-8&quot;</span>)  </span><br><span class=\"line\">word_emds = load_embeddings(glovefile)</span><br><span class=\"line\">sent1 = <span class=\"string\">&quot;people like this car&quot;</span></span><br><span class=\"line\">sent2 = <span class=\"string\">&quot;those guys enjoy driving that&quot;</span></span><br><span class=\"line\">sent3 = <span class=\"string\">&quot;Obama speaks to the media in Illinois.&quot;</span></span><br><span class=\"line\">sent4 = <span class=\"string\">&quot;The President greets the press in Chicago.&quot;</span></span><br><span class=\"line\">sent5 = <span class=\"string\">&quot;Beijing is China&#x27;s capital.&quot;</span></span><br><span class=\"line\">sent6 = <span class=\"string\">&quot;The capital of England is London.&quot;</span></span><br><span class=\"line\">print(WMD(sent1, sent2))</span><br><span class=\"line\">print(WMD(sent1, sent1))</span><br><span class=\"line\">print(WMD(sent3, sent4))</span><br><span class=\"line\">print(WMD(sent5, sent6))</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"3-相关论文及资料\"><a href=\"#3-相关论文及资料\" class=\"headerlink\" title=\"3. 相关论文及资料\"></a>3. 相关论文及资料</h2><p>[1] Kusner M, Sun Y, Kolkin N, et al. <a href=\"http://proceedings.mlr.press/v37/kusnerb15.pdf\">From word embeddings to document distances[C]</a>//International conference on machine learning. 2015: 957-966.<br>[2] Pele O, Werman M. <a href=\"http://www.cs.ucf.edu/courses/cap6412/spr2014/papers/pele-ICCV2009.pdf\">Fast and Robust Earth Mover’s Distances[J]</a>.<br>[3]Rubner Y, Tomasi C, Guibas L J. <a href=\"http://www.cs.cmu.edu/afs/.cs.cmu.edu/Web/People/efros/courses/AP06/Papers/rubner-jcviu-00.pdf\">The Earth Mover’s Distance as a Metric for Image Retrieval[J]</a>.<br>[4] CVXOPT官方文档：<a href=\"http://cvxopt.org/examples/tutorial/lp.html\">Solving a linear program</a>.<br>[5] CVXOPT官方文档：<a href=\"http://cvxopt.org/userguide/coneprog.html#linear-programming\">Linearing Programming</a>.<br>[6] Blog about CVXOPT LP: <a href=\"https://scaron.info/blog/linear-programming-in-python-with-cvxopt.html\">Linear Programming in Python with CVXOPT</a>.<br>[7] Gensim官方文档：<a href=\"https://radimrehurek.com/gensim/scripts/glove2word2vec.html\">glove2word2vec的使用</a>.</p>\n<p>以上为我对WMD论文的理解，文中若有错误之处，欢迎大家在评论区留言指正。</p>\n","site":{"data":{}},"excerpt":"<p>&emsp;&emsp;本文对《From Word Embeddings to Document Distances》论文（以下简称“WMD论文”）进行了讲解，并对其代码实现进行了介绍。  </p>\n<h2 id=\"1-论文讲解\"><a href=\"#1-论文讲解\" class=\"headerlink\" title=\"1. 论文讲解\"></a>1. 论文讲解</h2><p>&emsp;&emsp;在WMD论文中，作者提出了Word Mover’s Distance算法用来计算文档之间的距离，该算法基于word embedding来表示句子中的词向量。同时作者将文本距离计算问题看作是the Earth Mover’s Distance问题的一个实例，并提出了多种计算优化方法。以下是整个论文的框架，以及对WMD及其计算优化的详细讲解。<br></p>","more":"<p></p>\n<h3 id=\"1-1-论文框架\"><a href=\"#1-1-论文框架\" class=\"headerlink\" title=\"1.1 论文框架\"></a>1.1 论文框架</h3><p>&emsp;&emsp;本论文具体框架如下所示，其中的Algorithm讲解请见下方1.2小节：  </p>\n<center>![wmdpaper](2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances/WMDPaper.png)</center>  \n<center><b><font face=\"黑体\" size=\"2\">图1 WMD论文框架</font></b></center>  \n\n<h3 id=\"1-2-算法详解\"><a href=\"#1-2-算法详解\" class=\"headerlink\" title=\"1.2 算法详解\"></a>1.2 算法详解</h3><h4 id=\"1-2-1-Word2Vec-Embedding介绍\"><a href=\"#1-2-1-Word2Vec-Embedding介绍\" class=\"headerlink\" title=\"1.2.1 Word2Vec Embedding介绍\"></a>1.2.1 Word2Vec Embedding介绍</h4><p>&emsp;&emsp;Mikolov提出word2vec模型，该模型为无监督模型，使用神经网络语言模型生成词向量。在word2vec的skip-gram模型中，根据上下文词训练得到概率最大的中心词词向量，具体的公式如下：  </p>\n<script type=\"math/tex; mode=display\">\\frac 1T\\sum_{t=1}^T\\sum_{j\\in nb(t)}{\\log p(w_j|w_t)}\\tag{1}</script><p>其中nb(t)代表word$w_j$的上下文词。由于skip-gram模型简单的架构以及其中hierarchical softmax的应用，使得该模型可以在单机上每小时训练上亿单词。  </p>\n<h4 id=\"1-2-2-WMD算法讲解\"><a href=\"#1-2-2-WMD算法讲解\" class=\"headerlink\" title=\"1.2.2 WMD算法讲解\"></a>1.2.2 WMD算法讲解</h4><p>&emsp;&emsp;下面我们将详细讲解WMD算法的实现逻辑。  </p>\n<ul>\n<li><p><strong>nBow Representation</strong><br>该算法首先将文档用nBOW向量$d\\in R^n$表示，其中的每个元素代表对应的单词$i_{th}$在该文档中出现的次数（经过归一化处理），具体如下：  </p>\n<center>![nBow](2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances/nBow.jpg)</center>  \n<center><b><font face=\"黑体\" size=\"2\">图2 文档的nBOW表示</font></b></center>  \n</li>\n<li><p><strong>Word Travel Cost</strong><br>本论文的目标是在文本距离的计算过程中加入单词对之间的语义相似度，衡量单词语义相似度的其中一种方法是使用它们各自在w2v embedding向量空间中的欧式距离来表示，即为：  </p>\n<script type=\"math/tex; mode=display\">c(i, j) = \\rVert x_i - x_j \\rVert_2\\tag{2}</script><p>$c(i, j)$即表示两个word之间的“travel cost”。  </p>\n</li>\n<li><p><strong>Document Distance</strong><br>基于上述nBow representation和word之间的travel cost，对于两篇文档doc1、doc2，设其nBow representation分别为$d$和$d’$，doc1中的单词$i$ Travel到doc2中的单词$j$的个数为$T_{ij}$，两个单词的$travel cost=c(i, j)$，于是有：<center>![doc representation](2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances/docRep.jpg)</center><br><center><b><font face=\"黑体\" size=\"2\">图3 两文档映射的矩阵表示</font></b></center><br>综上，可以得知doc1和doc2之间的文本距离可表示为：  </p>\n<script type=\"math/tex; mode=display\">\\sum_{i,j}T_{i,j}c(i, j)\\tag{3}</script></li>\n<li><p><strong>Transportation Problem</strong><br>根据Document Distance中得到的文本距离公式，可以知道WMD算法需要解决的问题可表示为：  </p>\n<script type=\"math/tex; mode=display\">min_{T\\geq 0}\\sum_{i,j=1}^n{T_{ij}c(i, j)}\\tag{4}</script><script type=\"math/tex; mode=display\">\\begin{aligned}subject\\ to: \\sum_{j=1}^n{T_{ij} = d_i} \\quad \\forall i\\in \\{1,...,n\\} \\\\\\qquad \\qquad \\quad \\sum_{i=1}^n{T_{ij} = d'_j} \\quad \\forall j\\in \\{1,...,n\\}\\end{aligned}</script><p>上述优化问题可以看作是the Earth Mover’s Distance（EMD）问题的一个实例，EMD问题是一个研究很透彻的运输问题，已经有很成熟的解法。 </p>\n</li>\n<li><p><strong>Visualization</strong><br>最后以下图中几个句子为例，对WMD算法进行可视化总结：  </p>\n<center>![example](2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances/visualization.png)</center>  \n<center><b><font face=\"黑体\" size=\"2\">图4 WMD算法举例</font></b></center>  \n\n</li>\n</ul>\n<p>Top图中句子$D_1$和$D_2$分别和$D_0$计算文本距离，首先对各句子去除停用词，发现$D_1$和$D_2$ 与 $D_0$之间的BOW/TF-IDF距离都是相同的。但是在图中WMD算法中，我们观察到，各句子之间的word travel都在希望的语义相似的单词之间进行，进而得到最终的文本距离。  </p>\n<h4 id=\"1-2-3-WMD计算优化\"><a href=\"#1-2-3-WMD计算优化\" class=\"headerlink\" title=\"1.2.3 WMD计算优化\"></a>1.2.3 WMD计算优化</h4><p>&emsp;&emsp;WMD的最好平均时间复杂度为$O(p^3\\log p)$（p表示一篇文档中出现的不重复单词个数），对于文章中含有大量不重复单词或者文章数量众多的情况，wmd算法的代价太高。以下我们介绍几种利用求取WMD的lower bounds进行优化的算法：WCD &amp; RWMD。  </p>\n<ul>\n<li><strong>Word Centroid Distance</strong>  </li>\n</ul>\n<blockquote>\n<p>【向量范数定义】<br>如果向量 x∈Rn 的某个实值函数f(x)=||x||满足：  </p>\n<ol>\n<li>正定性： ||x||≥0，且||x||=0当且仅当x=0；  </li>\n<li>齐次性：对任意实数 α ，都有||αx||=|α| ||x||;  </li>\n<li>三角不等式：对任意x,y∈Rn，都有||x+y||≤||x||+||y||;<br>则称||x|| 为 Rn上的一个向量范数  </li>\n</ol>\n</blockquote>\n<p>&emsp;&emsp;根据上述向量范数的定义，可以推得“centroid”距离$\\rVert Xd-Xd’\\rVert$必定是WMD算法中两文本距离的lower bound：  </p>\n<script type=\"math/tex; mode=display\">\\begin{split}\\sum_{i,j=1}^n{T_{ij}c(i,j)} &= \\sum_{i,j=1}^n{T_{ij} \\rVert x_i - x'_j \\rVert _2} \\\\&= \\sum_{i,j=1}^n{\\rVert T_{ij}(x_i-x'_j) \\rVert_2} \\quad(范数的齐次性) \\\\&\\geq \\rVert \\sum_{i,j=1}^n{T_{ij}(x_i-x'_j) \\rVert_2} \\quad(范数的三角不等式性质) \\\\&=\\rVert \\sum_{i=1}^n\\left(\\sum_{j=1}^n{T_{ij}}\\right)x_i - \\sum_{j=1}^n\\left(\\sum_{i=1}^n{T_{ij}}\\right)x'_j \\rVert_2 \\\\&=\\rVert \\sum_{i=1}^n{d_ix_i}-\\sum_{j=1}^n{d'_jx'_j}\\rVert_2 \\\\&=\\rVert Xd - Xd' \\rVert_2\\end{split}\\tag{5}</script><p>上述WCD算法的时间复杂度为$O(dp)$，可以在求解topK相似的文档时使用该算法加快确定较小的候选集。  </p>\n<ul>\n<li><p><strong>Relaxed Word Moving Distance</strong><br>&emsp;&emsp;尽管WDC算法计算很快，但是它的结果与WMD算法差距不够小。在下面介绍的RWMD算法中，我们将去掉其中一个约束条件进而得到WMD算法的lower bound，该算法可以得到与WMD更相近的结果，于是RWMD的优化目标如下：  </p>\n<script type=\"math/tex; mode=display\">min_{T\\geq 0}\\sum_{i,j=1}^n{T_{ij}c(i, j)}\\tag{6}</script><script type=\"math/tex; mode=display\">subject\\ to: \\sum_{j=1}^n{T_{ij}=d_i\\quad \\forall i\\in \\{1,...,n\\}}</script><p>在RWMD算法中，可以将doc1中的每一个单词$i$都Travel到doc2中离它最近的单词$j$上来求得其最小值：<br>令<script type=\"math/tex\">T^*_{ij}=\\begin{cases} d_i\\quad if\\ j=argmin_jc(i,j) \\\\ 0 \\quad otherwise \\end{cases}</script>，有  </p>\n<script type=\"math/tex; mode=display\">\\begin{split}\\sum_j{T_{ij}c(i,j) \\geq \\sum_j{T_{ij}c(i, j^*)}} =c(i, j^*)\\sum_j{T_{ij}} \\\\=c(i, j^*)d_i = \\sum_j{T^*{ij}c(i,j)}\\end{split}\\tag{7}</script><p>分别去掉WMD的两个约束条件，得到两个近似结果$l_1(d, d’)$和$l_2(d, d’)$，于是RWMD算法的最终结果为：  </p>\n<script type=\"math/tex; mode=display\">l_r(d, d') = max(l_1(d, d'), l_2(d, d'))\\tag{8}</script><p>上述RWMD算法的时间复杂度为$O(p^2)$。  </p>\n</li>\n<li><p><strong>Prefetch and Prune</strong><br>&emsp;&emsp;本小结将介绍WCD+WMD+RWMD算法在问题“众多文档中寻找doc0的topK个最相似的文档”上的应用，具体解决步骤如下：<br>1）首先计算出所有文档到doc0的WCD距离，并且对于前k个文档计算具体的WMD距离；<br>2）对于剩余文档，计算其RWMD距离，并查看该距离是否要大于前k个文档的WMD距离：<br>&emsp;&emsp;如果大于，则可以prune该文档；<br>&emsp;&emsp;否则，计算该文档具体的WMD距离，看是否需要替换前k个文档。  </p>\n</li>\n</ul>\n<h2 id=\"2-代码详述\"><a href=\"#2-代码详述\" class=\"headerlink\" title=\"2. 代码详述\"></a>2. 代码详述</h2><h3 id=\"2-1-开源代码\"><a href=\"#2-1-开源代码\" class=\"headerlink\" title=\"2.1 开源代码\"></a>2.1 开源代码</h3><p>&emsp;&emsp;目前WMD算法的开源代码有：  </p>\n<ul>\n<li><p>WMD论文作者源码：<a href=\"https://github.com/mkusner/wmd\">Word Mover’s Distance (WMD) from Matthew J Kusner</a> ,使用单纯形法计算EMD，但单纯形法的时间复杂度不稳定，最大为指数级，大多数情况是超立方级；  </p>\n</li>\n<li><p>Gensim库中有WMD算法的实现，其调用了<a href=\"https://github.com/wmayner/pyemd\">pyemd</a>的c扩展，使用了Fast EMD算法，由于是python封装的wmd，计算非常慢，其调用方式为：from gensim.similarities import WmdSimilarity；</p>\n</li>\n<li><p>github上的<a href=\"https://github.com/src-d/wmd-relax\">Fast WMD</a>，同样是python封装c，另外在此项目中给出了RWMD算法的实现。  </p>\n</li>\n</ul>\n<h3 id=\"2-2-代码实现\"><a href=\"#2-2-代码实现\" class=\"headerlink\" title=\"2.2 代码实现\"></a>2.2 代码实现</h3><p>&emsp;&emsp;以下介绍下我对wmd算法的实现思路、使用工具以及代码复现。  </p>\n<h4 id=\"2-2-1-实现思路\"><a href=\"#2-2-1-实现思路\" class=\"headerlink\" title=\"2.2.1 实现思路\"></a>2.2.1 实现思路</h4><p>1）对文档进行分词（英文使用空格分开，中文使用分词器）；<br>2）对每个分词进行词嵌入表示（本文中使用训练好的glove词向量）；<br>3）将wmd算法转化为矩阵形式，其为lp最优化问题，可使用现成的lp最优化工具（本文中使用cvxopt包）解决。  </p>\n<h4 id=\"2-2-2-cvxopt-solver-lp接口\"><a href=\"#2-2-2-cvxopt-solver-lp接口\" class=\"headerlink\" title=\"2.2.2 cvxopt.solver.lp接口\"></a>2.2.2 cvxopt.solver.lp接口</h4><p>&emsp;&emsp;cvxopt.lp接口解决线性规划问题时，需先将问题转化为如下标准形式：  </p>\n<script type=\"math/tex; mode=display\">minimize\\quad c^Tx\\tag{9}</script><script type=\"math/tex; mode=display\">\\begin{aligned}subject\\ to:Gx\\leq h \\\\Ax=b \\end{aligned}</script><p>将wmd算法转换为此形式，具体如下图所示：</p>\n<center>![cvxopt Representation](2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances/cvxoptRep.jpg)</center>  \n<center><b><font face=\"黑体\" size=\"2\">图5 cvxopt矩阵表示</font></b></center>  \n\n<h4 id=\"2-2-3-代码复现\"><a href=\"#2-2-3-代码复现\" class=\"headerlink\" title=\"2.2.3 代码复现\"></a>2.2.3 代码复现</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> cvxopt <span class=\"keyword\">import</span> matrix, solvers</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 加载glove词向量</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">load_embeddings</span>(<span class=\"params\">glovefile</span>):</span></span><br><span class=\"line\">    word_emds = &#123;&#125;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> glovefile:</span><br><span class=\"line\">        eles = line.split(<span class=\"string\">&quot; &quot;</span>)</span><br><span class=\"line\">        word = eles[<span class=\"number\">0</span>]</span><br><span class=\"line\">        vector = list(map(float, eles[<span class=\"number\">1</span>:]))</span><br><span class=\"line\">        word_emds[word] = vector</span><br><span class=\"line\">    <span class=\"keyword\">return</span> word_emds</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 计算两个词向量之间的距离</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">get_distance</span>(<span class=\"params\">emd1, emd2</span>):</span></span><br><span class=\"line\">    result = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> idx <span class=\"keyword\">in</span> range(<span class=\"number\">0</span>, len(emd1)):</span><br><span class=\"line\">        val = pow(emd1[idx] - emd2[idx],<span class=\"number\">2</span>)</span><br><span class=\"line\">        result += val</span><br><span class=\"line\">    result = math.sqrt(result)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> result</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 词频统计（nBow）</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">get_nBow</span>(<span class=\"params\">word_list</span>):</span></span><br><span class=\"line\">    word_map = &#123;&#125;</span><br><span class=\"line\">    length = len(word_list)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> word <span class=\"keyword\">in</span> word_list:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> word <span class=\"keyword\">in</span> word_map.keys():</span><br><span class=\"line\">            word_map[word] += <span class=\"number\">1</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            word_map[word] = <span class=\"number\">1</span></span><br><span class=\"line\">    b = [val/length <span class=\"keyword\">for</span> val <span class=\"keyword\">in</span> word_map.values()]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> word_map, b</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">WMD</span> (<span class=\"params\">sent1, sent2</span>):</span></span><br><span class=\"line\">    <span class=\"comment\"># 0. 分词、词向量、词频统计等预处理</span></span><br><span class=\"line\">    word_list1 = sent1.split();</span><br><span class=\"line\">    word_list2 = sent2.split();</span><br><span class=\"line\">    </span><br><span class=\"line\">    word_map1, b1 = get_nBow(word_list1)</span><br><span class=\"line\">    word_map2, b2 = get_nBow(word_list2)    </span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># 1. 生成目标函数矩阵</span></span><br><span class=\"line\">    c_ij = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> word_map1.keys():</span><br><span class=\"line\">        <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> word_map2.keys():</span><br><span class=\"line\">            word_emds1 = []</span><br><span class=\"line\">            word_emds2 = []</span><br><span class=\"line\">            <span class=\"keyword\">if</span> i <span class=\"keyword\">in</span> word_emds:</span><br><span class=\"line\">                word_emds1 = word_emds[i]</span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                word_emds1 = [<span class=\"number\">0</span> <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(<span class=\"number\">100</span>)]</span><br><span class=\"line\">            <span class=\"keyword\">if</span> j <span class=\"keyword\">in</span> word_emds:</span><br><span class=\"line\">                word_emds2 = word_emds[j]</span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                word_emds2 = [<span class=\"number\">0</span> <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(<span class=\"number\">100</span>)]</span><br><span class=\"line\">            distance = get_distance(word_emds1, word_emds2)</span><br><span class=\"line\">            c_ij.append(distance)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># 2. 等式约束条件</span></span><br><span class=\"line\">    a = []</span><br><span class=\"line\">    length1 = len(word_map1)</span><br><span class=\"line\">    length2 = len(word_map2)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(length1):</span><br><span class=\"line\">        line = []</span><br><span class=\"line\">        start = [<span class=\"number\">0.0</span> <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(i*length2)]</span><br><span class=\"line\">        middle = [<span class=\"number\">1.0</span> <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(length2)]</span><br><span class=\"line\">        end = [<span class=\"number\">0.0</span> <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range((length1-i<span class=\"number\">-1</span>)*length2)]</span><br><span class=\"line\">        line.extend(start)</span><br><span class=\"line\">        line.extend(middle)</span><br><span class=\"line\">        line.extend(end)</span><br><span class=\"line\">        a.append(line)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(length2):</span><br><span class=\"line\">        line = []</span><br><span class=\"line\">        single = []</span><br><span class=\"line\">        start = [<span class=\"number\">0.0</span> <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(j)]</span><br><span class=\"line\">        end = [<span class=\"number\">0.0</span> <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(length2-j<span class=\"number\">-1</span>)]</span><br><span class=\"line\">        single.extend(start)</span><br><span class=\"line\">        single.append(<span class=\"number\">1.0</span>)</span><br><span class=\"line\">        single.extend(end)</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(length1):</span><br><span class=\"line\">            line.extend(single)</span><br><span class=\"line\">        a.append(line)        </span><br><span class=\"line\">        </span><br><span class=\"line\">    b = []</span><br><span class=\"line\">    b.extend(b1)</span><br><span class=\"line\">    b.extend(b2)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># 3. 不等式约束条件</span></span><br><span class=\"line\">    g = -np.eye(length1*length2)</span><br><span class=\"line\">    h = np.zeros((length1*length2))</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># 4. 应用cvxopt.solver</span></span><br><span class=\"line\">    c = matrix(c_ij)</span><br><span class=\"line\">    A = matrix(np.array(a))</span><br><span class=\"line\">    b = matrix(b)</span><br><span class=\"line\">    G = matrix(g)</span><br><span class=\"line\">    h = matrix(h) </span><br><span class=\"line\">    </span><br><span class=\"line\">    sol = solvers.lp(c,G,h,A,b,solver=<span class=\"string\">&#x27;glpk&#x27;</span>)</span><br><span class=\"line\">    wmd_dist = sol[<span class=\"string\">&#x27;primal objective&#x27;</span>]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> wmd_dist</span><br></pre></td></tr></table></figure>\n<p>测试代码：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">glovefile = open(<span class=\"string\">&quot;/root/nlpTool/glove.6B/glove.6B.100d.txt&quot;</span>,<span class=\"string\">&quot;r&quot;</span>,encoding=<span class=\"string\">&quot;utf-8&quot;</span>)  </span><br><span class=\"line\">word_emds = load_embeddings(glovefile)</span><br><span class=\"line\">sent1 = <span class=\"string\">&quot;people like this car&quot;</span></span><br><span class=\"line\">sent2 = <span class=\"string\">&quot;those guys enjoy driving that&quot;</span></span><br><span class=\"line\">sent3 = <span class=\"string\">&quot;Obama speaks to the media in Illinois.&quot;</span></span><br><span class=\"line\">sent4 = <span class=\"string\">&quot;The President greets the press in Chicago.&quot;</span></span><br><span class=\"line\">sent5 = <span class=\"string\">&quot;Beijing is China&#x27;s capital.&quot;</span></span><br><span class=\"line\">sent6 = <span class=\"string\">&quot;The capital of England is London.&quot;</span></span><br><span class=\"line\">print(WMD(sent1, sent2))</span><br><span class=\"line\">print(WMD(sent1, sent1))</span><br><span class=\"line\">print(WMD(sent3, sent4))</span><br><span class=\"line\">print(WMD(sent5, sent6))</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"3-相关论文及资料\"><a href=\"#3-相关论文及资料\" class=\"headerlink\" title=\"3. 相关论文及资料\"></a>3. 相关论文及资料</h2><p>[1] Kusner M, Sun Y, Kolkin N, et al. <a href=\"http://proceedings.mlr.press/v37/kusnerb15.pdf\">From word embeddings to document distances[C]</a>//International conference on machine learning. 2015: 957-966.<br>[2] Pele O, Werman M. <a href=\"http://www.cs.ucf.edu/courses/cap6412/spr2014/papers/pele-ICCV2009.pdf\">Fast and Robust Earth Mover’s Distances[J]</a>.<br>[3]Rubner Y, Tomasi C, Guibas L J. <a href=\"http://www.cs.cmu.edu/afs/.cs.cmu.edu/Web/People/efros/courses/AP06/Papers/rubner-jcviu-00.pdf\">The Earth Mover’s Distance as a Metric for Image Retrieval[J]</a>.<br>[4] CVXOPT官方文档：<a href=\"http://cvxopt.org/examples/tutorial/lp.html\">Solving a linear program</a>.<br>[5] CVXOPT官方文档：<a href=\"http://cvxopt.org/userguide/coneprog.html#linear-programming\">Linearing Programming</a>.<br>[6] Blog about CVXOPT LP: <a href=\"https://scaron.info/blog/linear-programming-in-python-with-cvxopt.html\">Linear Programming in Python with CVXOPT</a>.<br>[7] Gensim官方文档：<a href=\"https://radimrehurek.com/gensim/scripts/glove2word2vec.html\">glove2word2vec的使用</a>.</p>\n<p>以上为我对WMD论文的理解，文中若有错误之处，欢迎大家在评论区留言指正。</p>"}],"PostAsset":[{"_id":"source/_posts/2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances/cvxoptRep.jpg","slug":"cvxoptRep.jpg","post":"ckvi8p0a80003ggsjhw9t8uzo","modified":0,"renderable":0},{"_id":"source/_posts/2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances/dataset.png","slug":"dataset.png","post":"ckvi8p0a80003ggsjhw9t8uzo","modified":0,"renderable":0},{"_id":"source/_posts/2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances/docRep.jpg","slug":"docRep.jpg","post":"ckvi8p0a80003ggsjhw9t8uzo","modified":0,"renderable":0},{"_id":"source/_posts/2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances/nBow.jpg","slug":"nBow.jpg","post":"ckvi8p0a80003ggsjhw9t8uzo","modified":0,"renderable":0},{"_id":"source/_posts/2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances/prefetch.png","slug":"prefetch.png","post":"ckvi8p0a80003ggsjhw9t8uzo","modified":0,"renderable":0},{"_id":"source/_posts/2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances/visualization.png","slug":"visualization.png","post":"ckvi8p0a80003ggsjhw9t8uzo","modified":0,"renderable":0},{"_id":"source/_posts/2020-10-03-WMD论文详解及代码介绍From-Word-Embeddings-to-Document-Distances/WMDPaper.png","slug":"WMDPaper.png","post":"ckvi8p0a80003ggsjhw9t8uzo","modified":0,"renderable":0}],"PostCategory":[{"post_id":"ckvi8p0a80003ggsjhw9t8uzo","category_id":"ckvi8p0ac0004ggsjft095716","_id":"ckvi8p0af0007ggsj9hw52u10"}],"PostTag":[{"post_id":"ckvi8p0a80003ggsjhw9t8uzo","tag_id":"ckvi8p0ae0005ggsja7cwc3x6","_id":"ckvi8p0af0006ggsj4yub79vy"}],"Tag":[{"name":"paper","_id":"ckvi8p0ae0005ggsja7cwc3x6"}]}}